{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>value__kurtosis_p6</th>\n",
       "      <th>value__linear_trend__attr_\"intercept\"_p6</th>\n",
       "      <th>value__linear_trend__attr_\"slope\"_p6</th>\n",
       "      <th>value__quantile__q_0.01_p6</th>\n",
       "      <th>value__quantile__q_0.99_p6</th>\n",
       "      <th>value__skewness_p6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rougher.input.feed_fe</td>\n",
       "      <td>-0.284606</td>\n",
       "      <td>8.290417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.100378</td>\n",
       "      <td>6.100378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougher.input.feed_fe</td>\n",
       "      <td>-0.284606</td>\n",
       "      <td>6.100378</td>\n",
       "      <td>0.060735</td>\n",
       "      <td>6.100985</td>\n",
       "      <td>6.160506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougher.input.feed_fe</td>\n",
       "      <td>-0.284606</td>\n",
       "      <td>6.117944</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>6.100700</td>\n",
       "      <td>6.160220</td>\n",
       "      <td>1.237514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rougher.input.feed_fe</td>\n",
       "      <td>1.047950</td>\n",
       "      <td>6.137694</td>\n",
       "      <td>-0.021587</td>\n",
       "      <td>6.045021</td>\n",
       "      <td>6.159774</td>\n",
       "      <td>-0.366498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rougher.input.feed_fe</td>\n",
       "      <td>-0.780750</td>\n",
       "      <td>6.135780</td>\n",
       "      <td>-0.019673</td>\n",
       "      <td>6.044013</td>\n",
       "      <td>6.159327</td>\n",
       "      <td>0.345700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  level_0  value__kurtosis_p6  \\\n",
       "id                                              \n",
       "1   rougher.input.feed_fe           -0.284606   \n",
       "2   rougher.input.feed_fe           -0.284606   \n",
       "3   rougher.input.feed_fe           -0.284606   \n",
       "4   rougher.input.feed_fe            1.047950   \n",
       "5   rougher.input.feed_fe           -0.780750   \n",
       "\n",
       "    value__linear_trend__attr_\"intercept\"_p6  \\\n",
       "id                                             \n",
       "1                                   8.290417   \n",
       "2                                   6.100378   \n",
       "3                                   6.117944   \n",
       "4                                   6.137694   \n",
       "5                                   6.135780   \n",
       "\n",
       "    value__linear_trend__attr_\"slope\"_p6  value__quantile__q_0.01_p6  \\\n",
       "id                                                                     \n",
       "1                               0.000000                    6.100378   \n",
       "2                               0.060735                    6.100985   \n",
       "3                               0.008038                    6.100700   \n",
       "4                              -0.021587                    6.045021   \n",
       "5                              -0.019673                    6.044013   \n",
       "\n",
       "    value__quantile__q_0.99_p6  value__skewness_p6  \n",
       "id                                                  \n",
       "1                     6.100378            0.000000  \n",
       "2                     6.160506            0.000000  \n",
       "3                     6.160220            1.237514  \n",
       "4                     6.159774           -0.366498  \n",
       "5                     6.159327            0.345700  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from ocp_table_tpot.globals import Globals as gd\n",
    "from tpot import TPOTRegressor\n",
    "sys.path.insert(0,'..')\n",
    "from src.models.model import HistoricalMedian,XGBoost,LinearModel,RF,KNN,SVM,mase,TimeSeriesSplitImproved\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from skgarden.quantile import RandomForestQuantileRegressor\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "from tpot.builtins import StackingEstimator\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from catboost import CatBoostRegressor,Pool,cv\n",
    "\n",
    "\n",
    "df_tsfresh = pd.read_pickle(f'../data/processed/train_test_tsfresh_6.pkl').reset_index(level = 0)\n",
    "data_dict = pd.read_pickle(f'../data/processed/data_dict_all.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__kurtosis_p24_primary_cleaner.input.copper_sulfate</th>\n",
       "      <th>value__kurtosis_p24_primary_cleaner.input.depressant</th>\n",
       "      <th>value__kurtosis_p24_primary_cleaner.input.feed_size</th>\n",
       "      <th>value__kurtosis_p24_primary_cleaner.input.xanthate</th>\n",
       "      <th>value__kurtosis_p24_primary_cleaner.state.floatbank8_a_air</th>\n",
       "      <th>value__kurtosis_p24_rougher.input.feed_fe</th>\n",
       "      <th>value__kurtosis_p24_rougher.input.feed_pb</th>\n",
       "      <th>value__kurtosis_p24_rougher.input.feed_rate</th>\n",
       "      <th>value__kurtosis_p24_rougher.input.feed_sol</th>\n",
       "      <th>value__kurtosis_p24_rougher.input.feed_zn</th>\n",
       "      <th>...</th>\n",
       "      <th>value__skewness_p24_primary_cleaner.state.floatbank8_a_air</th>\n",
       "      <th>value__skewness_p24_rougher.input.feed_fe</th>\n",
       "      <th>value__skewness_p24_rougher.input.feed_pb</th>\n",
       "      <th>value__skewness_p24_rougher.input.feed_rate</th>\n",
       "      <th>value__skewness_p24_rougher.input.feed_sol</th>\n",
       "      <th>value__skewness_p24_rougher.input.feed_zn</th>\n",
       "      <th>value__skewness_p24_rougher.input.floatbank10_copper_sulfate</th>\n",
       "      <th>value__skewness_p24_rougher.input.floatbank11_xanthate</th>\n",
       "      <th>value__skewness_p24_rougher.state.floatbank10_b_air</th>\n",
       "      <th>value__skewness_p24_secondary_cleaner.state.floatbank5_a_air</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278897</td>\n",
       "      <td>0.053372</td>\n",
       "      <td>-0.176947</td>\n",
       "      <td>-0.154139</td>\n",
       "      <td>-0.214268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100395</td>\n",
       "      <td>0.641409</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058141</td>\n",
       "      <td>-0.263996</td>\n",
       "      <td>-0.259988</td>\n",
       "      <td>-0.860201</td>\n",
       "      <td>-0.837851</td>\n",
       "      <td>-0.323986</td>\n",
       "      <td>-0.252958</td>\n",
       "      <td>-0.368861</td>\n",
       "      <td>-0.033020</td>\n",
       "      <td>-0.038588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.278897</td>\n",
       "      <td>0.053372</td>\n",
       "      <td>-0.176947</td>\n",
       "      <td>-0.154139</td>\n",
       "      <td>-0.214268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100395</td>\n",
       "      <td>0.641409</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058141</td>\n",
       "      <td>-0.263996</td>\n",
       "      <td>-0.259988</td>\n",
       "      <td>-0.860201</td>\n",
       "      <td>-0.837851</td>\n",
       "      <td>-0.323986</td>\n",
       "      <td>-0.252958</td>\n",
       "      <td>-0.368861</td>\n",
       "      <td>-0.033020</td>\n",
       "      <td>-0.038588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.278897</td>\n",
       "      <td>0.053372</td>\n",
       "      <td>-0.176947</td>\n",
       "      <td>-0.154139</td>\n",
       "      <td>-0.214268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100395</td>\n",
       "      <td>0.641409</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058006</td>\n",
       "      <td>1.237514</td>\n",
       "      <td>-1.581082</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>1.437744</td>\n",
       "      <td>-1.708960</td>\n",
       "      <td>-1.351549</td>\n",
       "      <td>1.725034</td>\n",
       "      <td>0.664107</td>\n",
       "      <td>-1.403274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.742939</td>\n",
       "      <td>-5.661114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.441736</td>\n",
       "      <td>-0.975720</td>\n",
       "      <td>1.047950</td>\n",
       "      <td>-1.018959</td>\n",
       "      <td>1.847391</td>\n",
       "      <td>-5.236670</td>\n",
       "      <td>1.551123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.909072</td>\n",
       "      <td>-0.366498</td>\n",
       "      <td>-0.868829</td>\n",
       "      <td>1.447526</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>-1.423029</td>\n",
       "      <td>-1.836277</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>1.243404</td>\n",
       "      <td>-0.188030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666613</td>\n",
       "      <td>-2.156010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.078796</td>\n",
       "      <td>0.531150</td>\n",
       "      <td>-0.780750</td>\n",
       "      <td>0.735865</td>\n",
       "      <td>-2.847330</td>\n",
       "      <td>0.963174</td>\n",
       "      <td>1.352728</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.295466</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>-1.141334</td>\n",
       "      <td>0.333572</td>\n",
       "      <td>-1.059807</td>\n",
       "      <td>-1.380184</td>\n",
       "      <td>-1.708991</td>\n",
       "      <td>-0.605228</td>\n",
       "      <td>1.521760</td>\n",
       "      <td>0.430250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.234524</td>\n",
       "      <td>-1.249255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.824896</td>\n",
       "      <td>1.552501</td>\n",
       "      <td>3.965021</td>\n",
       "      <td>-1.741339</td>\n",
       "      <td>-2.477429</td>\n",
       "      <td>0.297311</td>\n",
       "      <td>-2.136735</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.552102</td>\n",
       "      <td>-1.867800</td>\n",
       "      <td>-0.379789</td>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.652324</td>\n",
       "      <td>-0.519982</td>\n",
       "      <td>-0.706237</td>\n",
       "      <td>-0.964531</td>\n",
       "      <td>1.260495</td>\n",
       "      <td>-0.130560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.888178</td>\n",
       "      <td>-1.451355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.347661</td>\n",
       "      <td>2.521608</td>\n",
       "      <td>4.559010</td>\n",
       "      <td>-1.019515</td>\n",
       "      <td>-2.243768</td>\n",
       "      <td>-0.886157</td>\n",
       "      <td>-1.669840</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.766990</td>\n",
       "      <td>-1.953136</td>\n",
       "      <td>-0.499886</td>\n",
       "      <td>0.311307</td>\n",
       "      <td>-0.153746</td>\n",
       "      <td>-0.365018</td>\n",
       "      <td>-0.643948</td>\n",
       "      <td>-1.226172</td>\n",
       "      <td>1.283002</td>\n",
       "      <td>-0.189063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.642567</td>\n",
       "      <td>-1.293400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.456864</td>\n",
       "      <td>3.386386</td>\n",
       "      <td>2.338624</td>\n",
       "      <td>-0.865392</td>\n",
       "      <td>-2.073712</td>\n",
       "      <td>-0.476416</td>\n",
       "      <td>-1.341732</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.955110</td>\n",
       "      <td>-1.446646</td>\n",
       "      <td>-0.644398</td>\n",
       "      <td>0.111052</td>\n",
       "      <td>-0.346535</td>\n",
       "      <td>-0.631005</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>2.109900</td>\n",
       "      <td>0.940207</td>\n",
       "      <td>-0.244638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.554306</td>\n",
       "      <td>-1.001338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.668334</td>\n",
       "      <td>4.138874</td>\n",
       "      <td>-0.144432</td>\n",
       "      <td>-0.687321</td>\n",
       "      <td>-1.068359</td>\n",
       "      <td>-0.066269</td>\n",
       "      <td>-1.008853</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.118285</td>\n",
       "      <td>-0.874414</td>\n",
       "      <td>-0.616591</td>\n",
       "      <td>0.333733</td>\n",
       "      <td>-0.344318</td>\n",
       "      <td>-0.791393</td>\n",
       "      <td>0.598911</td>\n",
       "      <td>1.285839</td>\n",
       "      <td>1.133190</td>\n",
       "      <td>-0.482942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.408837</td>\n",
       "      <td>-0.660945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.120564</td>\n",
       "      <td>4.803398</td>\n",
       "      <td>-0.812605</td>\n",
       "      <td>-0.609016</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.371682</td>\n",
       "      <td>-0.720809</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.251644</td>\n",
       "      <td>-0.544432</td>\n",
       "      <td>-0.594845</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>-0.408715</td>\n",
       "      <td>-0.837967</td>\n",
       "      <td>0.752999</td>\n",
       "      <td>0.808516</td>\n",
       "      <td>1.140621</td>\n",
       "      <td>-0.345575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.799758</td>\n",
       "      <td>-0.304122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.241728</td>\n",
       "      <td>5.539247</td>\n",
       "      <td>-0.651140</td>\n",
       "      <td>-0.530416</td>\n",
       "      <td>-1.074190</td>\n",
       "      <td>1.062577</td>\n",
       "      <td>-0.514241</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.395041</td>\n",
       "      <td>-0.457193</td>\n",
       "      <td>-0.450139</td>\n",
       "      <td>0.371232</td>\n",
       "      <td>0.619870</td>\n",
       "      <td>-0.788417</td>\n",
       "      <td>0.636061</td>\n",
       "      <td>0.484025</td>\n",
       "      <td>1.268390</td>\n",
       "      <td>-0.529503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.506474</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.168785</td>\n",
       "      <td>6.266730</td>\n",
       "      <td>-1.162662</td>\n",
       "      <td>-0.399840</td>\n",
       "      <td>-0.755824</td>\n",
       "      <td>-0.144341</td>\n",
       "      <td>-0.227099</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.529739</td>\n",
       "      <td>-0.277472</td>\n",
       "      <td>-0.611379</td>\n",
       "      <td>0.501918</td>\n",
       "      <td>0.484257</td>\n",
       "      <td>-0.935379</td>\n",
       "      <td>0.437370</td>\n",
       "      <td>0.240944</td>\n",
       "      <td>1.376548</td>\n",
       "      <td>-0.660087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.104375</td>\n",
       "      <td>0.411594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.085939</td>\n",
       "      <td>6.923673</td>\n",
       "      <td>-1.093777</td>\n",
       "      <td>-0.108931</td>\n",
       "      <td>-0.551383</td>\n",
       "      <td>-0.590757</td>\n",
       "      <td>-0.061354</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.644929</td>\n",
       "      <td>-0.432711</td>\n",
       "      <td>-0.698885</td>\n",
       "      <td>0.479758</td>\n",
       "      <td>0.260449</td>\n",
       "      <td>-1.001661</td>\n",
       "      <td>0.219953</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>1.478157</td>\n",
       "      <td>-0.566638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.478980</td>\n",
       "      <td>0.764184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.949524</td>\n",
       "      <td>7.624024</td>\n",
       "      <td>-0.909176</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>-0.557110</td>\n",
       "      <td>-0.678578</td>\n",
       "      <td>0.169583</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.759338</td>\n",
       "      <td>-0.557710</td>\n",
       "      <td>-0.801609</td>\n",
       "      <td>0.353307</td>\n",
       "      <td>0.337844</td>\n",
       "      <td>-1.105226</td>\n",
       "      <td>0.042417</td>\n",
       "      <td>-0.104321</td>\n",
       "      <td>1.587134</td>\n",
       "      <td>-0.617217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.667759</td>\n",
       "      <td>1.112222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.792139</td>\n",
       "      <td>8.243223</td>\n",
       "      <td>-0.698017</td>\n",
       "      <td>0.200382</td>\n",
       "      <td>-0.685415</td>\n",
       "      <td>-0.707386</td>\n",
       "      <td>0.430454</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.849141</td>\n",
       "      <td>-0.597167</td>\n",
       "      <td>-0.865316</td>\n",
       "      <td>0.194165</td>\n",
       "      <td>0.408523</td>\n",
       "      <td>-1.208510</td>\n",
       "      <td>-0.109274</td>\n",
       "      <td>-0.241377</td>\n",
       "      <td>1.500761</td>\n",
       "      <td>-0.512268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.709838</td>\n",
       "      <td>1.455681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.625328</td>\n",
       "      <td>8.939868</td>\n",
       "      <td>-0.540323</td>\n",
       "      <td>0.213566</td>\n",
       "      <td>-0.816604</td>\n",
       "      <td>-0.940932</td>\n",
       "      <td>0.638586</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.959333</td>\n",
       "      <td>-0.708668</td>\n",
       "      <td>-0.535357</td>\n",
       "      <td>0.043818</td>\n",
       "      <td>0.365021</td>\n",
       "      <td>-1.279943</td>\n",
       "      <td>-0.231819</td>\n",
       "      <td>-0.356847</td>\n",
       "      <td>1.596267</td>\n",
       "      <td>-0.625535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.746829</td>\n",
       "      <td>1.794709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.652187</td>\n",
       "      <td>9.552558</td>\n",
       "      <td>-0.494099</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>-0.944128</td>\n",
       "      <td>-1.155517</td>\n",
       "      <td>0.812365</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.051241</td>\n",
       "      <td>-0.707093</td>\n",
       "      <td>-0.483388</td>\n",
       "      <td>-0.084534</td>\n",
       "      <td>0.285857</td>\n",
       "      <td>-1.327928</td>\n",
       "      <td>-0.136040</td>\n",
       "      <td>-0.432845</td>\n",
       "      <td>1.513689</td>\n",
       "      <td>-0.706220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.702551</td>\n",
       "      <td>2.130488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.825304</td>\n",
       "      <td>10.231423</td>\n",
       "      <td>-0.203067</td>\n",
       "      <td>-0.121519</td>\n",
       "      <td>-1.015449</td>\n",
       "      <td>-1.196208</td>\n",
       "      <td>0.918414</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.152495</td>\n",
       "      <td>-0.349228</td>\n",
       "      <td>-0.445557</td>\n",
       "      <td>-0.193787</td>\n",
       "      <td>0.268521</td>\n",
       "      <td>-1.329519</td>\n",
       "      <td>-0.114026</td>\n",
       "      <td>-0.506152</td>\n",
       "      <td>1.585030</td>\n",
       "      <td>-0.789007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.676913</td>\n",
       "      <td>2.466224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.933105</td>\n",
       "      <td>10.915693</td>\n",
       "      <td>-0.100142</td>\n",
       "      <td>-0.153569</td>\n",
       "      <td>-1.063458</td>\n",
       "      <td>-1.353308</td>\n",
       "      <td>1.189000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.249987</td>\n",
       "      <td>-0.299126</td>\n",
       "      <td>-0.526479</td>\n",
       "      <td>-0.260003</td>\n",
       "      <td>0.141201</td>\n",
       "      <td>-1.413357</td>\n",
       "      <td>-0.193868</td>\n",
       "      <td>-0.580362</td>\n",
       "      <td>1.589391</td>\n",
       "      <td>-0.874524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.643743</td>\n",
       "      <td>2.802094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.990815</td>\n",
       "      <td>11.597174</td>\n",
       "      <td>0.066548</td>\n",
       "      <td>-0.226565</td>\n",
       "      <td>-1.034818</td>\n",
       "      <td>-1.448574</td>\n",
       "      <td>1.314320</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.344240</td>\n",
       "      <td>-0.329588</td>\n",
       "      <td>-0.431321</td>\n",
       "      <td>-0.356931</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>-1.437748</td>\n",
       "      <td>-0.260680</td>\n",
       "      <td>-0.555578</td>\n",
       "      <td>1.504301</td>\n",
       "      <td>-0.956758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.580296</td>\n",
       "      <td>3.138039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.007509</td>\n",
       "      <td>12.250480</td>\n",
       "      <td>-0.066628</td>\n",
       "      <td>-0.194220</td>\n",
       "      <td>-0.974105</td>\n",
       "      <td>-1.469498</td>\n",
       "      <td>1.199929</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.429237</td>\n",
       "      <td>-0.384867</td>\n",
       "      <td>-0.221814</td>\n",
       "      <td>-0.445986</td>\n",
       "      <td>-0.004671</td>\n",
       "      <td>-1.091163</td>\n",
       "      <td>-0.242694</td>\n",
       "      <td>-0.494596</td>\n",
       "      <td>1.491553</td>\n",
       "      <td>-0.938923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.426305</td>\n",
       "      <td>3.305506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.003146</td>\n",
       "      <td>12.835340</td>\n",
       "      <td>0.084821</td>\n",
       "      <td>-0.355025</td>\n",
       "      <td>-0.878931</td>\n",
       "      <td>-1.443421</td>\n",
       "      <td>1.009476</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.498380</td>\n",
       "      <td>-0.400543</td>\n",
       "      <td>-0.231805</td>\n",
       "      <td>-0.525052</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>-0.873989</td>\n",
       "      <td>-0.244774</td>\n",
       "      <td>-0.357249</td>\n",
       "      <td>1.478397</td>\n",
       "      <td>-0.996041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.368117</td>\n",
       "      <td>2.834220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.977877</td>\n",
       "      <td>13.376736</td>\n",
       "      <td>2.068760</td>\n",
       "      <td>-0.251758</td>\n",
       "      <td>-0.797134</td>\n",
       "      <td>-1.461897</td>\n",
       "      <td>1.208718</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.558007</td>\n",
       "      <td>-1.143724</td>\n",
       "      <td>-0.291563</td>\n",
       "      <td>-0.601800</td>\n",
       "      <td>-0.079103</td>\n",
       "      <td>-0.918574</td>\n",
       "      <td>-0.327956</td>\n",
       "      <td>-0.305635</td>\n",
       "      <td>1.547092</td>\n",
       "      <td>-0.959424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.288080</td>\n",
       "      <td>2.238088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.937956</td>\n",
       "      <td>13.926457</td>\n",
       "      <td>1.724780</td>\n",
       "      <td>-0.451360</td>\n",
       "      <td>-0.675700</td>\n",
       "      <td>-1.471963</td>\n",
       "      <td>0.523724</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.618187</td>\n",
       "      <td>-0.939013</td>\n",
       "      <td>-0.311314</td>\n",
       "      <td>-0.663494</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>-0.876548</td>\n",
       "      <td>-0.241043</td>\n",
       "      <td>-0.318792</td>\n",
       "      <td>1.473735</td>\n",
       "      <td>-0.989114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.319901</td>\n",
       "      <td>2.298094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.947955</td>\n",
       "      <td>15.105982</td>\n",
       "      <td>1.248972</td>\n",
       "      <td>0.688735</td>\n",
       "      <td>-0.275476</td>\n",
       "      <td>-1.457395</td>\n",
       "      <td>1.154500</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.528227</td>\n",
       "      <td>-0.738803</td>\n",
       "      <td>-0.816008</td>\n",
       "      <td>-0.807595</td>\n",
       "      <td>-0.284315</td>\n",
       "      <td>-1.159079</td>\n",
       "      <td>-0.245985</td>\n",
       "      <td>-0.432910</td>\n",
       "      <td>-0.338378</td>\n",
       "      <td>-1.237850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.324304</td>\n",
       "      <td>0.881027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.935514</td>\n",
       "      <td>-1.313489</td>\n",
       "      <td>0.544297</td>\n",
       "      <td>0.288511</td>\n",
       "      <td>-0.375225</td>\n",
       "      <td>-1.226685</td>\n",
       "      <td>0.345733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>-0.556122</td>\n",
       "      <td>-0.702612</td>\n",
       "      <td>-0.750209</td>\n",
       "      <td>-0.452733</td>\n",
       "      <td>-0.949097</td>\n",
       "      <td>-0.259612</td>\n",
       "      <td>-0.501432</td>\n",
       "      <td>-0.076968</td>\n",
       "      <td>-1.218004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.205210</td>\n",
       "      <td>0.297114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.943281</td>\n",
       "      <td>-1.283771</td>\n",
       "      <td>1.797032</td>\n",
       "      <td>0.395032</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>-0.931711</td>\n",
       "      <td>0.109817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219101</td>\n",
       "      <td>-1.081037</td>\n",
       "      <td>-0.752721</td>\n",
       "      <td>-0.935843</td>\n",
       "      <td>-0.648499</td>\n",
       "      <td>-0.855931</td>\n",
       "      <td>-0.370402</td>\n",
       "      <td>-0.667771</td>\n",
       "      <td>-0.226741</td>\n",
       "      <td>-1.383096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.931308</td>\n",
       "      <td>-0.576822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.946142</td>\n",
       "      <td>-1.314894</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.731563</td>\n",
       "      <td>0.941433</td>\n",
       "      <td>-0.648854</td>\n",
       "      <td>0.122525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320580</td>\n",
       "      <td>-1.052660</td>\n",
       "      <td>-0.881985</td>\n",
       "      <td>-1.168332</td>\n",
       "      <td>-0.831709</td>\n",
       "      <td>-0.860288</td>\n",
       "      <td>-0.487594</td>\n",
       "      <td>-0.786585</td>\n",
       "      <td>-0.297322</td>\n",
       "      <td>-1.454488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.563705</td>\n",
       "      <td>-1.160045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.938693</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>0.209406</td>\n",
       "      <td>1.705130</td>\n",
       "      <td>1.862167</td>\n",
       "      <td>-0.404830</td>\n",
       "      <td>0.857886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483096</td>\n",
       "      <td>-0.827511</td>\n",
       "      <td>-1.112602</td>\n",
       "      <td>-1.392952</td>\n",
       "      <td>-0.930877</td>\n",
       "      <td>-1.038948</td>\n",
       "      <td>-0.548283</td>\n",
       "      <td>-0.840721</td>\n",
       "      <td>-0.197756</td>\n",
       "      <td>-1.325225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.348975</td>\n",
       "      <td>-1.562616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.963361</td>\n",
       "      <td>-0.789729</td>\n",
       "      <td>0.360661</td>\n",
       "      <td>2.828995</td>\n",
       "      <td>2.785834</td>\n",
       "      <td>0.245761</td>\n",
       "      <td>1.925398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623160</td>\n",
       "      <td>-0.886010</td>\n",
       "      <td>-1.378934</td>\n",
       "      <td>-1.628029</td>\n",
       "      <td>-1.120028</td>\n",
       "      <td>-1.286744</td>\n",
       "      <td>-0.551626</td>\n",
       "      <td>-0.667371</td>\n",
       "      <td>-0.156639</td>\n",
       "      <td>-0.988746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22686</th>\n",
       "      <td>1.411991</td>\n",
       "      <td>3.857471</td>\n",
       "      <td>-1.522746</td>\n",
       "      <td>-1.111609</td>\n",
       "      <td>-1.899127</td>\n",
       "      <td>14.017832</td>\n",
       "      <td>6.209861</td>\n",
       "      <td>4.449797</td>\n",
       "      <td>15.208375</td>\n",
       "      <td>14.888988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175253</td>\n",
       "      <td>-3.403333</td>\n",
       "      <td>-1.280983</td>\n",
       "      <td>-2.009262</td>\n",
       "      <td>-3.634528</td>\n",
       "      <td>-3.546164</td>\n",
       "      <td>-0.786787</td>\n",
       "      <td>-1.811834</td>\n",
       "      <td>-0.153559</td>\n",
       "      <td>0.151219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22687</th>\n",
       "      <td>1.219647</td>\n",
       "      <td>3.225989</td>\n",
       "      <td>-1.670556</td>\n",
       "      <td>-0.515713</td>\n",
       "      <td>-1.768199</td>\n",
       "      <td>15.946649</td>\n",
       "      <td>8.965590</td>\n",
       "      <td>5.108387</td>\n",
       "      <td>15.495483</td>\n",
       "      <td>16.546930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266254</td>\n",
       "      <td>-3.807569</td>\n",
       "      <td>-2.438809</td>\n",
       "      <td>-2.181580</td>\n",
       "      <td>-3.691705</td>\n",
       "      <td>-3.876215</td>\n",
       "      <td>-0.800738</td>\n",
       "      <td>-1.999890</td>\n",
       "      <td>-0.104158</td>\n",
       "      <td>0.332312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22688</th>\n",
       "      <td>0.997217</td>\n",
       "      <td>2.679810</td>\n",
       "      <td>-1.735331</td>\n",
       "      <td>0.333274</td>\n",
       "      <td>-1.602895</td>\n",
       "      <td>16.235511</td>\n",
       "      <td>9.832458</td>\n",
       "      <td>5.261773</td>\n",
       "      <td>16.088438</td>\n",
       "      <td>16.554054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356041</td>\n",
       "      <td>-3.851237</td>\n",
       "      <td>-2.599074</td>\n",
       "      <td>-2.238406</td>\n",
       "      <td>-3.792503</td>\n",
       "      <td>-3.872116</td>\n",
       "      <td>-0.925188</td>\n",
       "      <td>-2.224131</td>\n",
       "      <td>-0.131669</td>\n",
       "      <td>0.519651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22689</th>\n",
       "      <td>1.184410</td>\n",
       "      <td>2.217098</td>\n",
       "      <td>-1.806551</td>\n",
       "      <td>1.681814</td>\n",
       "      <td>-1.399631</td>\n",
       "      <td>16.223142</td>\n",
       "      <td>9.876717</td>\n",
       "      <td>5.275314</td>\n",
       "      <td>16.302514</td>\n",
       "      <td>16.709034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442579</td>\n",
       "      <td>-3.848732</td>\n",
       "      <td>-2.625165</td>\n",
       "      <td>-2.241248</td>\n",
       "      <td>-3.831909</td>\n",
       "      <td>-3.898826</td>\n",
       "      <td>-1.078631</td>\n",
       "      <td>-2.475394</td>\n",
       "      <td>-0.226151</td>\n",
       "      <td>0.719381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22690</th>\n",
       "      <td>1.404185</td>\n",
       "      <td>1.861185</td>\n",
       "      <td>-1.839368</td>\n",
       "      <td>3.829890</td>\n",
       "      <td>-1.156846</td>\n",
       "      <td>16.326623</td>\n",
       "      <td>10.277431</td>\n",
       "      <td>5.357614</td>\n",
       "      <td>16.469365</td>\n",
       "      <td>17.090635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>-3.868224</td>\n",
       "      <td>-2.725084</td>\n",
       "      <td>-2.262235</td>\n",
       "      <td>-3.864071</td>\n",
       "      <td>-3.962066</td>\n",
       "      <td>-1.157073</td>\n",
       "      <td>-2.473122</td>\n",
       "      <td>-0.370265</td>\n",
       "      <td>0.937403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22691</th>\n",
       "      <td>1.620006</td>\n",
       "      <td>1.575132</td>\n",
       "      <td>-1.895327</td>\n",
       "      <td>8.103589</td>\n",
       "      <td>-0.880518</td>\n",
       "      <td>16.292567</td>\n",
       "      <td>10.376757</td>\n",
       "      <td>5.712057</td>\n",
       "      <td>16.472674</td>\n",
       "      <td>17.284955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585244</td>\n",
       "      <td>-3.868227</td>\n",
       "      <td>-2.770523</td>\n",
       "      <td>-2.366445</td>\n",
       "      <td>-3.863483</td>\n",
       "      <td>-3.999136</td>\n",
       "      <td>-1.180168</td>\n",
       "      <td>-2.472614</td>\n",
       "      <td>-0.254252</td>\n",
       "      <td>1.181987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22692</th>\n",
       "      <td>1.565638</td>\n",
       "      <td>1.354780</td>\n",
       "      <td>-1.968773</td>\n",
       "      <td>16.528657</td>\n",
       "      <td>-0.601146</td>\n",
       "      <td>15.802968</td>\n",
       "      <td>8.640978</td>\n",
       "      <td>5.904611</td>\n",
       "      <td>16.468104</td>\n",
       "      <td>16.849824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614807</td>\n",
       "      <td>-3.780891</td>\n",
       "      <td>-2.350312</td>\n",
       "      <td>-2.408684</td>\n",
       "      <td>-3.862380</td>\n",
       "      <td>-3.927406</td>\n",
       "      <td>-1.190211</td>\n",
       "      <td>-2.472933</td>\n",
       "      <td>-0.346023</td>\n",
       "      <td>1.470814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22693</th>\n",
       "      <td>1.326293</td>\n",
       "      <td>1.190242</td>\n",
       "      <td>-1.947483</td>\n",
       "      <td>11.644699</td>\n",
       "      <td>-0.432752</td>\n",
       "      <td>14.352162</td>\n",
       "      <td>6.560167</td>\n",
       "      <td>5.862924</td>\n",
       "      <td>17.087174</td>\n",
       "      <td>15.418055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567008</td>\n",
       "      <td>-3.495602</td>\n",
       "      <td>-1.638019</td>\n",
       "      <td>-2.399009</td>\n",
       "      <td>-3.967179</td>\n",
       "      <td>-3.654907</td>\n",
       "      <td>-1.206616</td>\n",
       "      <td>-2.506979</td>\n",
       "      <td>-0.406844</td>\n",
       "      <td>1.826080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694</th>\n",
       "      <td>1.076875</td>\n",
       "      <td>1.084526</td>\n",
       "      <td>-1.864775</td>\n",
       "      <td>0.800106</td>\n",
       "      <td>-0.609282</td>\n",
       "      <td>13.837495</td>\n",
       "      <td>5.500908</td>\n",
       "      <td>5.478862</td>\n",
       "      <td>17.274244</td>\n",
       "      <td>14.811784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377527</td>\n",
       "      <td>-3.405969</td>\n",
       "      <td>-1.468775</td>\n",
       "      <td>-2.291341</td>\n",
       "      <td>-3.995980</td>\n",
       "      <td>-3.553496</td>\n",
       "      <td>-1.531869</td>\n",
       "      <td>-2.544535</td>\n",
       "      <td>-0.259078</td>\n",
       "      <td>2.278574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22695</th>\n",
       "      <td>1.139587</td>\n",
       "      <td>1.004570</td>\n",
       "      <td>-1.714728</td>\n",
       "      <td>0.778072</td>\n",
       "      <td>-1.998208</td>\n",
       "      <td>13.725628</td>\n",
       "      <td>5.249413</td>\n",
       "      <td>5.285131</td>\n",
       "      <td>17.472828</td>\n",
       "      <td>14.595325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151888</td>\n",
       "      <td>-3.390963</td>\n",
       "      <td>-1.503685</td>\n",
       "      <td>-2.225140</td>\n",
       "      <td>-4.026524</td>\n",
       "      <td>-3.523752</td>\n",
       "      <td>-1.659311</td>\n",
       "      <td>-2.618114</td>\n",
       "      <td>-0.318330</td>\n",
       "      <td>2.904465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22696</th>\n",
       "      <td>1.016966</td>\n",
       "      <td>1.107586</td>\n",
       "      <td>-1.486350</td>\n",
       "      <td>0.875554</td>\n",
       "      <td>-2.061572</td>\n",
       "      <td>13.306613</td>\n",
       "      <td>4.608710</td>\n",
       "      <td>5.124741</td>\n",
       "      <td>17.725327</td>\n",
       "      <td>14.067102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196253</td>\n",
       "      <td>-3.319952</td>\n",
       "      <td>-1.429577</td>\n",
       "      <td>-2.165712</td>\n",
       "      <td>-4.066097</td>\n",
       "      <td>-3.437032</td>\n",
       "      <td>-1.643544</td>\n",
       "      <td>-2.870043</td>\n",
       "      <td>-0.447909</td>\n",
       "      <td>3.405399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22697</th>\n",
       "      <td>0.847155</td>\n",
       "      <td>1.097025</td>\n",
       "      <td>-1.161589</td>\n",
       "      <td>1.000531</td>\n",
       "      <td>-2.062487</td>\n",
       "      <td>12.415446</td>\n",
       "      <td>3.649199</td>\n",
       "      <td>5.129823</td>\n",
       "      <td>17.655384</td>\n",
       "      <td>12.950715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197970</td>\n",
       "      <td>-3.156327</td>\n",
       "      <td>-1.182631</td>\n",
       "      <td>-2.166860</td>\n",
       "      <td>-4.049845</td>\n",
       "      <td>-3.224690</td>\n",
       "      <td>-1.651317</td>\n",
       "      <td>-2.887603</td>\n",
       "      <td>-0.549385</td>\n",
       "      <td>4.610704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22698</th>\n",
       "      <td>1.400331</td>\n",
       "      <td>1.095088</td>\n",
       "      <td>-0.711677</td>\n",
       "      <td>1.049488</td>\n",
       "      <td>-2.084487</td>\n",
       "      <td>12.263383</td>\n",
       "      <td>3.588046</td>\n",
       "      <td>5.832486</td>\n",
       "      <td>17.605009</td>\n",
       "      <td>12.563069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231618</td>\n",
       "      <td>-3.148351</td>\n",
       "      <td>-1.268739</td>\n",
       "      <td>-2.291696</td>\n",
       "      <td>-4.039331</td>\n",
       "      <td>-3.168623</td>\n",
       "      <td>-1.684580</td>\n",
       "      <td>-2.886208</td>\n",
       "      <td>-0.522542</td>\n",
       "      <td>-0.009403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22699</th>\n",
       "      <td>2.546726</td>\n",
       "      <td>1.086883</td>\n",
       "      <td>-0.600776</td>\n",
       "      <td>1.279180</td>\n",
       "      <td>-1.951889</td>\n",
       "      <td>12.412361</td>\n",
       "      <td>3.971896</td>\n",
       "      <td>5.714208</td>\n",
       "      <td>17.623692</td>\n",
       "      <td>12.620341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415757</td>\n",
       "      <td>-3.192564</td>\n",
       "      <td>-1.427592</td>\n",
       "      <td>-2.246287</td>\n",
       "      <td>-4.039112</td>\n",
       "      <td>-3.191450</td>\n",
       "      <td>-1.725410</td>\n",
       "      <td>-2.886208</td>\n",
       "      <td>-0.517308</td>\n",
       "      <td>0.105907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22700</th>\n",
       "      <td>3.433973</td>\n",
       "      <td>1.070741</td>\n",
       "      <td>-0.595830</td>\n",
       "      <td>1.322564</td>\n",
       "      <td>-1.731343</td>\n",
       "      <td>12.084947</td>\n",
       "      <td>3.656061</td>\n",
       "      <td>5.675542</td>\n",
       "      <td>17.610279</td>\n",
       "      <td>12.443171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609148</td>\n",
       "      <td>-3.147672</td>\n",
       "      <td>-1.423737</td>\n",
       "      <td>-2.213072</td>\n",
       "      <td>-4.036134</td>\n",
       "      <td>-3.176837</td>\n",
       "      <td>-1.839363</td>\n",
       "      <td>-3.232049</td>\n",
       "      <td>-0.570115</td>\n",
       "      <td>0.045203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22701</th>\n",
       "      <td>3.984192</td>\n",
       "      <td>1.080352</td>\n",
       "      <td>-0.587996</td>\n",
       "      <td>2.232017</td>\n",
       "      <td>-1.400311</td>\n",
       "      <td>11.635140</td>\n",
       "      <td>3.465072</td>\n",
       "      <td>5.515813</td>\n",
       "      <td>17.669441</td>\n",
       "      <td>11.955170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817447</td>\n",
       "      <td>-3.075442</td>\n",
       "      <td>-1.426690</td>\n",
       "      <td>-2.146464</td>\n",
       "      <td>-4.043260</td>\n",
       "      <td>-3.102448</td>\n",
       "      <td>-1.909829</td>\n",
       "      <td>-3.190895</td>\n",
       "      <td>-0.433502</td>\n",
       "      <td>0.035741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22702</th>\n",
       "      <td>4.256954</td>\n",
       "      <td>1.085161</td>\n",
       "      <td>-0.577401</td>\n",
       "      <td>2.107680</td>\n",
       "      <td>-0.919771</td>\n",
       "      <td>2.454632</td>\n",
       "      <td>-0.512384</td>\n",
       "      <td>5.238111</td>\n",
       "      <td>9.187952</td>\n",
       "      <td>1.818604</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.048280</td>\n",
       "      <td>-0.986669</td>\n",
       "      <td>-0.246957</td>\n",
       "      <td>-2.048024</td>\n",
       "      <td>-2.624308</td>\n",
       "      <td>-0.892490</td>\n",
       "      <td>-1.940938</td>\n",
       "      <td>-2.941106</td>\n",
       "      <td>-0.405984</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22703</th>\n",
       "      <td>4.496906</td>\n",
       "      <td>1.090747</td>\n",
       "      <td>-0.564215</td>\n",
       "      <td>2.360143</td>\n",
       "      <td>-0.220603</td>\n",
       "      <td>-1.147427</td>\n",
       "      <td>-1.330729</td>\n",
       "      <td>5.117123</td>\n",
       "      <td>0.836026</td>\n",
       "      <td>-1.354387</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313032</td>\n",
       "      <td>0.173827</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>-1.979828</td>\n",
       "      <td>-0.791803</td>\n",
       "      <td>0.063209</td>\n",
       "      <td>-1.983548</td>\n",
       "      <td>-2.402737</td>\n",
       "      <td>-0.537429</td>\n",
       "      <td>0.186096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22704</th>\n",
       "      <td>4.566818</td>\n",
       "      <td>1.098883</td>\n",
       "      <td>-0.548653</td>\n",
       "      <td>-0.909620</td>\n",
       "      <td>0.827445</td>\n",
       "      <td>-1.074894</td>\n",
       "      <td>-1.307197</td>\n",
       "      <td>5.138934</td>\n",
       "      <td>1.055938</td>\n",
       "      <td>-1.226713</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.630326</td>\n",
       "      <td>0.084209</td>\n",
       "      <td>-0.063747</td>\n",
       "      <td>-1.941957</td>\n",
       "      <td>-0.933113</td>\n",
       "      <td>-0.065354</td>\n",
       "      <td>-1.990903</td>\n",
       "      <td>-1.974486</td>\n",
       "      <td>-0.539636</td>\n",
       "      <td>0.206912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22705</th>\n",
       "      <td>4.429791</td>\n",
       "      <td>1.107154</td>\n",
       "      <td>-0.530995</td>\n",
       "      <td>-0.831827</td>\n",
       "      <td>2.496837</td>\n",
       "      <td>-1.003475</td>\n",
       "      <td>-1.348273</td>\n",
       "      <td>5.931076</td>\n",
       "      <td>0.886368</td>\n",
       "      <td>-1.109894</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.034105</td>\n",
       "      <td>0.156532</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>-2.131994</td>\n",
       "      <td>-0.851820</td>\n",
       "      <td>-0.051745</td>\n",
       "      <td>-1.870168</td>\n",
       "      <td>-1.597831</td>\n",
       "      <td>-0.457935</td>\n",
       "      <td>0.152530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22706</th>\n",
       "      <td>5.433998</td>\n",
       "      <td>1.045691</td>\n",
       "      <td>-0.511608</td>\n",
       "      <td>-0.793382</td>\n",
       "      <td>5.458160</td>\n",
       "      <td>-0.874546</td>\n",
       "      <td>-1.203183</td>\n",
       "      <td>3.484252</td>\n",
       "      <td>2.064866</td>\n",
       "      <td>-1.073845</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.595788</td>\n",
       "      <td>0.056451</td>\n",
       "      <td>-0.106869</td>\n",
       "      <td>-1.292190</td>\n",
       "      <td>-1.030039</td>\n",
       "      <td>-0.075057</td>\n",
       "      <td>-2.297273</td>\n",
       "      <td>-1.758908</td>\n",
       "      <td>-1.012429</td>\n",
       "      <td>0.722837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22707</th>\n",
       "      <td>5.633099</td>\n",
       "      <td>2.203917</td>\n",
       "      <td>-0.490969</td>\n",
       "      <td>-0.754500</td>\n",
       "      <td>11.846393</td>\n",
       "      <td>-0.884588</td>\n",
       "      <td>-1.200770</td>\n",
       "      <td>-1.515005</td>\n",
       "      <td>0.412066</td>\n",
       "      <td>-1.077137</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.498935</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>-0.120907</td>\n",
       "      <td>0.190363</td>\n",
       "      <td>-0.360570</td>\n",
       "      <td>-0.024562</td>\n",
       "      <td>-0.348878</td>\n",
       "      <td>-1.751814</td>\n",
       "      <td>-1.047206</td>\n",
       "      <td>0.695911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22708</th>\n",
       "      <td>-0.523905</td>\n",
       "      <td>0.971237</td>\n",
       "      <td>-0.469707</td>\n",
       "      <td>-0.699868</td>\n",
       "      <td>23.870066</td>\n",
       "      <td>-0.870318</td>\n",
       "      <td>-1.066751</td>\n",
       "      <td>-1.436822</td>\n",
       "      <td>0.035577</td>\n",
       "      <td>-1.081658</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.879631</td>\n",
       "      <td>-0.102723</td>\n",
       "      <td>-0.258309</td>\n",
       "      <td>0.244128</td>\n",
       "      <td>-0.451085</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>-0.123327</td>\n",
       "      <td>-1.651485</td>\n",
       "      <td>-0.345806</td>\n",
       "      <td>4.638382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22709</th>\n",
       "      <td>-0.892063</td>\n",
       "      <td>-1.948888</td>\n",
       "      <td>-0.448644</td>\n",
       "      <td>-0.679853</td>\n",
       "      <td>23.923437</td>\n",
       "      <td>-0.729136</td>\n",
       "      <td>-0.859243</td>\n",
       "      <td>-1.240629</td>\n",
       "      <td>0.070504</td>\n",
       "      <td>-0.941472</td>\n",
       "      <td>...</td>\n",
       "      <td>4.887828</td>\n",
       "      <td>-0.234905</td>\n",
       "      <td>-0.376417</td>\n",
       "      <td>0.314706</td>\n",
       "      <td>-0.699720</td>\n",
       "      <td>-0.024542</td>\n",
       "      <td>-0.164571</td>\n",
       "      <td>-1.650969</td>\n",
       "      <td>-0.496049</td>\n",
       "      <td>3.504189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22710</th>\n",
       "      <td>-0.865400</td>\n",
       "      <td>-1.878746</td>\n",
       "      <td>0.334248</td>\n",
       "      <td>-0.531543</td>\n",
       "      <td>23.885395</td>\n",
       "      <td>-0.527326</td>\n",
       "      <td>-0.468679</td>\n",
       "      <td>-0.988274</td>\n",
       "      <td>-0.122482</td>\n",
       "      <td>-0.746260</td>\n",
       "      <td>...</td>\n",
       "      <td>4.882352</td>\n",
       "      <td>-0.413616</td>\n",
       "      <td>-0.511321</td>\n",
       "      <td>0.393914</td>\n",
       "      <td>-0.646414</td>\n",
       "      <td>-0.058314</td>\n",
       "      <td>-0.015063</td>\n",
       "      <td>-1.651134</td>\n",
       "      <td>-0.422899</td>\n",
       "      <td>3.504909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22711</th>\n",
       "      <td>-0.946798</td>\n",
       "      <td>-1.621879</td>\n",
       "      <td>1.715443</td>\n",
       "      <td>-0.543443</td>\n",
       "      <td>23.829661</td>\n",
       "      <td>-0.151767</td>\n",
       "      <td>-0.204353</td>\n",
       "      <td>-0.891043</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>-0.823593</td>\n",
       "      <td>...</td>\n",
       "      <td>4.874318</td>\n",
       "      <td>-0.536726</td>\n",
       "      <td>-0.536540</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>-0.313647</td>\n",
       "      <td>-0.072308</td>\n",
       "      <td>-0.064728</td>\n",
       "      <td>-1.650555</td>\n",
       "      <td>-0.499954</td>\n",
       "      <td>3.505069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22712</th>\n",
       "      <td>-1.049295</td>\n",
       "      <td>-1.242246</td>\n",
       "      <td>4.060871</td>\n",
       "      <td>-0.180621</td>\n",
       "      <td>23.757934</td>\n",
       "      <td>0.058366</td>\n",
       "      <td>-0.217311</td>\n",
       "      <td>-0.895182</td>\n",
       "      <td>-0.086642</td>\n",
       "      <td>-0.793588</td>\n",
       "      <td>...</td>\n",
       "      <td>4.863955</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.402503</td>\n",
       "      <td>0.408772</td>\n",
       "      <td>-0.078217</td>\n",
       "      <td>-0.095619</td>\n",
       "      <td>-0.039393</td>\n",
       "      <td>-1.650902</td>\n",
       "      <td>-0.438673</td>\n",
       "      <td>3.508671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22713</th>\n",
       "      <td>-1.115657</td>\n",
       "      <td>-0.696297</td>\n",
       "      <td>8.766643</td>\n",
       "      <td>-0.036223</td>\n",
       "      <td>12.517869</td>\n",
       "      <td>-0.255605</td>\n",
       "      <td>-0.288732</td>\n",
       "      <td>-0.669110</td>\n",
       "      <td>-0.099929</td>\n",
       "      <td>0.123587</td>\n",
       "      <td>...</td>\n",
       "      <td>3.560618</td>\n",
       "      <td>-0.244130</td>\n",
       "      <td>-0.368462</td>\n",
       "      <td>0.508279</td>\n",
       "      <td>-0.104775</td>\n",
       "      <td>-0.493448</td>\n",
       "      <td>-0.056668</td>\n",
       "      <td>-1.650364</td>\n",
       "      <td>-0.208201</td>\n",
       "      <td>2.823914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22714</th>\n",
       "      <td>-1.110122</td>\n",
       "      <td>0.109162</td>\n",
       "      <td>22.527091</td>\n",
       "      <td>21.971757</td>\n",
       "      <td>6.772027</td>\n",
       "      <td>-0.420624</td>\n",
       "      <td>-0.020997</td>\n",
       "      <td>1.324657</td>\n",
       "      <td>-0.067296</td>\n",
       "      <td>0.510753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.768172</td>\n",
       "      <td>-0.161340</td>\n",
       "      <td>-0.489077</td>\n",
       "      <td>1.096337</td>\n",
       "      <td>-0.082733</td>\n",
       "      <td>-0.782838</td>\n",
       "      <td>0.112227</td>\n",
       "      <td>-1.650802</td>\n",
       "      <td>-0.088848</td>\n",
       "      <td>2.394611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22715</th>\n",
       "      <td>-1.105289</td>\n",
       "      <td>0.650188</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.719148</td>\n",
       "      <td>3.266787</td>\n",
       "      <td>-0.388576</td>\n",
       "      <td>0.129817</td>\n",
       "      <td>1.251465</td>\n",
       "      <td>-0.359026</td>\n",
       "      <td>0.229893</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166352</td>\n",
       "      <td>-0.278169</td>\n",
       "      <td>-0.692602</td>\n",
       "      <td>1.256587</td>\n",
       "      <td>-0.117435</td>\n",
       "      <td>-0.870948</td>\n",
       "      <td>0.115846</td>\n",
       "      <td>-1.650756</td>\n",
       "      <td>-0.169631</td>\n",
       "      <td>1.937874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22715 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value__kurtosis_p24_primary_cleaner.input.copper_sulfate  \\\n",
       "id                                                                \n",
       "1                                              -0.278897          \n",
       "2                                              -0.278897          \n",
       "3                                              -0.278897          \n",
       "4                                              -1.742939          \n",
       "5                                               0.666613          \n",
       "6                                              -1.234524          \n",
       "7                                              -1.888178          \n",
       "8                                              -1.642567          \n",
       "9                                              -0.554306          \n",
       "10                                              0.408837          \n",
       "11                                              0.799758          \n",
       "12                                             -0.506474          \n",
       "13                                             -1.104375          \n",
       "14                                             -1.478980          \n",
       "15                                             -1.667759          \n",
       "16                                             -1.709838          \n",
       "17                                             -1.746829          \n",
       "18                                             -1.702551          \n",
       "19                                             -1.676913          \n",
       "20                                             -1.643743          \n",
       "21                                             -1.580296          \n",
       "22                                             -1.426305          \n",
       "23                                             -1.368117          \n",
       "24                                             -1.288080          \n",
       "25                                             -1.319901          \n",
       "26                                             -1.324304          \n",
       "27                                             -1.205210          \n",
       "28                                             -0.931308          \n",
       "29                                             -0.563705          \n",
       "30                                             -0.348975          \n",
       "...                                                  ...          \n",
       "22686                                           1.411991          \n",
       "22687                                           1.219647          \n",
       "22688                                           0.997217          \n",
       "22689                                           1.184410          \n",
       "22690                                           1.404185          \n",
       "22691                                           1.620006          \n",
       "22692                                           1.565638          \n",
       "22693                                           1.326293          \n",
       "22694                                           1.076875          \n",
       "22695                                           1.139587          \n",
       "22696                                           1.016966          \n",
       "22697                                           0.847155          \n",
       "22698                                           1.400331          \n",
       "22699                                           2.546726          \n",
       "22700                                           3.433973          \n",
       "22701                                           3.984192          \n",
       "22702                                           4.256954          \n",
       "22703                                           4.496906          \n",
       "22704                                           4.566818          \n",
       "22705                                           4.429791          \n",
       "22706                                           5.433998          \n",
       "22707                                           5.633099          \n",
       "22708                                          -0.523905          \n",
       "22709                                          -0.892063          \n",
       "22710                                          -0.865400          \n",
       "22711                                          -0.946798          \n",
       "22712                                          -1.049295          \n",
       "22713                                          -1.115657          \n",
       "22714                                          -1.110122          \n",
       "22715                                          -1.105289          \n",
       "\n",
       "       value__kurtosis_p24_primary_cleaner.input.depressant  \\\n",
       "id                                                            \n",
       "1                                               0.053372      \n",
       "2                                               0.053372      \n",
       "3                                               0.053372      \n",
       "4                                              -5.661114      \n",
       "5                                              -2.156010      \n",
       "6                                              -1.249255      \n",
       "7                                              -1.451355      \n",
       "8                                              -1.293400      \n",
       "9                                              -1.001338      \n",
       "10                                             -0.660945      \n",
       "11                                             -0.304122      \n",
       "12                                              0.054948      \n",
       "13                                              0.411594      \n",
       "14                                              0.764184      \n",
       "15                                              1.112222      \n",
       "16                                              1.455681      \n",
       "17                                              1.794709      \n",
       "18                                              2.130488      \n",
       "19                                              2.466224      \n",
       "20                                              2.802094      \n",
       "21                                              3.138039      \n",
       "22                                              3.305506      \n",
       "23                                              2.834220      \n",
       "24                                              2.238088      \n",
       "25                                              2.298094      \n",
       "26                                              0.881027      \n",
       "27                                              0.297114      \n",
       "28                                             -0.576822      \n",
       "29                                             -1.160045      \n",
       "30                                             -1.562616      \n",
       "...                                                  ...      \n",
       "22686                                           3.857471      \n",
       "22687                                           3.225989      \n",
       "22688                                           2.679810      \n",
       "22689                                           2.217098      \n",
       "22690                                           1.861185      \n",
       "22691                                           1.575132      \n",
       "22692                                           1.354780      \n",
       "22693                                           1.190242      \n",
       "22694                                           1.084526      \n",
       "22695                                           1.004570      \n",
       "22696                                           1.107586      \n",
       "22697                                           1.097025      \n",
       "22698                                           1.095088      \n",
       "22699                                           1.086883      \n",
       "22700                                           1.070741      \n",
       "22701                                           1.080352      \n",
       "22702                                           1.085161      \n",
       "22703                                           1.090747      \n",
       "22704                                           1.098883      \n",
       "22705                                           1.107154      \n",
       "22706                                           1.045691      \n",
       "22707                                           2.203917      \n",
       "22708                                           0.971237      \n",
       "22709                                          -1.948888      \n",
       "22710                                          -1.878746      \n",
       "22711                                          -1.621879      \n",
       "22712                                          -1.242246      \n",
       "22713                                          -0.696297      \n",
       "22714                                           0.109162      \n",
       "22715                                           0.650188      \n",
       "\n",
       "       value__kurtosis_p24_primary_cleaner.input.feed_size  \\\n",
       "id                                                           \n",
       "1                                              -0.176947     \n",
       "2                                              -0.176947     \n",
       "3                                              -0.176947     \n",
       "4                                               0.000000     \n",
       "5                                               0.000000     \n",
       "6                                               0.000000     \n",
       "7                                               0.000000     \n",
       "8                                               0.000000     \n",
       "9                                               0.000000     \n",
       "10                                              0.000000     \n",
       "11                                              0.000000     \n",
       "12                                              0.000000     \n",
       "13                                              0.000000     \n",
       "14                                              0.000000     \n",
       "15                                              0.000000     \n",
       "16                                              0.000000     \n",
       "17                                              0.000000     \n",
       "18                                              0.000000     \n",
       "19                                              0.000000     \n",
       "20                                              0.000000     \n",
       "21                                              0.000000     \n",
       "22                                              0.000000     \n",
       "23                                              0.000000     \n",
       "24                                              0.000000     \n",
       "25                                              0.000000     \n",
       "26                                              0.000000     \n",
       "27                                              0.000000     \n",
       "28                                              0.000000     \n",
       "29                                              0.000000     \n",
       "30                                              0.000000     \n",
       "...                                                  ...     \n",
       "22686                                          -1.522746     \n",
       "22687                                          -1.670556     \n",
       "22688                                          -1.735331     \n",
       "22689                                          -1.806551     \n",
       "22690                                          -1.839368     \n",
       "22691                                          -1.895327     \n",
       "22692                                          -1.968773     \n",
       "22693                                          -1.947483     \n",
       "22694                                          -1.864775     \n",
       "22695                                          -1.714728     \n",
       "22696                                          -1.486350     \n",
       "22697                                          -1.161589     \n",
       "22698                                          -0.711677     \n",
       "22699                                          -0.600776     \n",
       "22700                                          -0.595830     \n",
       "22701                                          -0.587996     \n",
       "22702                                          -0.577401     \n",
       "22703                                          -0.564215     \n",
       "22704                                          -0.548653     \n",
       "22705                                          -0.530995     \n",
       "22706                                          -0.511608     \n",
       "22707                                          -0.490969     \n",
       "22708                                          -0.469707     \n",
       "22709                                          -0.448644     \n",
       "22710                                           0.334248     \n",
       "22711                                           1.715443     \n",
       "22712                                           4.060871     \n",
       "22713                                           8.766643     \n",
       "22714                                          22.527091     \n",
       "22715                                          24.000000     \n",
       "\n",
       "       value__kurtosis_p24_primary_cleaner.input.xanthate  \\\n",
       "id                                                          \n",
       "1                                              -0.154139    \n",
       "2                                              -0.154139    \n",
       "3                                              -0.154139    \n",
       "4                                              -1.441736    \n",
       "5                                              -1.078796    \n",
       "6                                               1.824896    \n",
       "7                                               4.347661    \n",
       "8                                              -0.456864    \n",
       "9                                              -1.668334    \n",
       "10                                             -2.120564    \n",
       "11                                             -2.241728    \n",
       "12                                             -2.168785    \n",
       "13                                             -2.085939    \n",
       "14                                             -1.949524    \n",
       "15                                             -1.792139    \n",
       "16                                             -1.625328    \n",
       "17                                             -1.652187    \n",
       "18                                             -1.825304    \n",
       "19                                             -1.933105    \n",
       "20                                             -1.990815    \n",
       "21                                             -2.007509    \n",
       "22                                             -2.003146    \n",
       "23                                             -1.977877    \n",
       "24                                             -1.937956    \n",
       "25                                             -1.947955    \n",
       "26                                             -1.935514    \n",
       "27                                             -1.943281    \n",
       "28                                             -1.946142    \n",
       "29                                             -1.938693    \n",
       "30                                             -1.963361    \n",
       "...                                                  ...    \n",
       "22686                                          -1.111609    \n",
       "22687                                          -0.515713    \n",
       "22688                                           0.333274    \n",
       "22689                                           1.681814    \n",
       "22690                                           3.829890    \n",
       "22691                                           8.103589    \n",
       "22692                                          16.528657    \n",
       "22693                                          11.644699    \n",
       "22694                                           0.800106    \n",
       "22695                                           0.778072    \n",
       "22696                                           0.875554    \n",
       "22697                                           1.000531    \n",
       "22698                                           1.049488    \n",
       "22699                                           1.279180    \n",
       "22700                                           1.322564    \n",
       "22701                                           2.232017    \n",
       "22702                                           2.107680    \n",
       "22703                                           2.360143    \n",
       "22704                                          -0.909620    \n",
       "22705                                          -0.831827    \n",
       "22706                                          -0.793382    \n",
       "22707                                          -0.754500    \n",
       "22708                                          -0.699868    \n",
       "22709                                          -0.679853    \n",
       "22710                                          -0.531543    \n",
       "22711                                          -0.543443    \n",
       "22712                                          -0.180621    \n",
       "22713                                          -0.036223    \n",
       "22714                                          21.971757    \n",
       "22715                                          15.719148    \n",
       "\n",
       "       value__kurtosis_p24_primary_cleaner.state.floatbank8_a_air  \\\n",
       "id                                                                  \n",
       "1                                              -0.214268            \n",
       "2                                              -0.214268            \n",
       "3                                              -0.214268            \n",
       "4                                              -0.975720            \n",
       "5                                               0.531150            \n",
       "6                                               1.552501            \n",
       "7                                               2.521608            \n",
       "8                                               3.386386            \n",
       "9                                               4.138874            \n",
       "10                                              4.803398            \n",
       "11                                              5.539247            \n",
       "12                                              6.266730            \n",
       "13                                              6.923673            \n",
       "14                                              7.624024            \n",
       "15                                              8.243223            \n",
       "16                                              8.939868            \n",
       "17                                              9.552558            \n",
       "18                                             10.231423            \n",
       "19                                             10.915693            \n",
       "20                                             11.597174            \n",
       "21                                             12.250480            \n",
       "22                                             12.835340            \n",
       "23                                             13.376736            \n",
       "24                                             13.926457            \n",
       "25                                             15.105982            \n",
       "26                                             -1.313489            \n",
       "27                                             -1.283771            \n",
       "28                                             -1.314894            \n",
       "29                                             -1.148641            \n",
       "30                                             -0.789729            \n",
       "...                                                  ...            \n",
       "22686                                          -1.899127            \n",
       "22687                                          -1.768199            \n",
       "22688                                          -1.602895            \n",
       "22689                                          -1.399631            \n",
       "22690                                          -1.156846            \n",
       "22691                                          -0.880518            \n",
       "22692                                          -0.601146            \n",
       "22693                                          -0.432752            \n",
       "22694                                          -0.609282            \n",
       "22695                                          -1.998208            \n",
       "22696                                          -2.061572            \n",
       "22697                                          -2.062487            \n",
       "22698                                          -2.084487            \n",
       "22699                                          -1.951889            \n",
       "22700                                          -1.731343            \n",
       "22701                                          -1.400311            \n",
       "22702                                          -0.919771            \n",
       "22703                                          -0.220603            \n",
       "22704                                           0.827445            \n",
       "22705                                           2.496837            \n",
       "22706                                           5.458160            \n",
       "22707                                          11.846393            \n",
       "22708                                          23.870066            \n",
       "22709                                          23.923437            \n",
       "22710                                          23.885395            \n",
       "22711                                          23.829661            \n",
       "22712                                          23.757934            \n",
       "22713                                          12.517869            \n",
       "22714                                           6.772027            \n",
       "22715                                           3.266787            \n",
       "\n",
       "       value__kurtosis_p24_rougher.input.feed_fe  \\\n",
       "id                                                 \n",
       "1                                       0.000000   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       1.047950   \n",
       "5                                      -0.780750   \n",
       "6                                       3.965021   \n",
       "7                                       4.559010   \n",
       "8                                       2.338624   \n",
       "9                                      -0.144432   \n",
       "10                                     -0.812605   \n",
       "11                                     -0.651140   \n",
       "12                                     -1.162662   \n",
       "13                                     -1.093777   \n",
       "14                                     -0.909176   \n",
       "15                                     -0.698017   \n",
       "16                                     -0.540323   \n",
       "17                                     -0.494099   \n",
       "18                                     -0.203067   \n",
       "19                                     -0.100142   \n",
       "20                                      0.066548   \n",
       "21                                     -0.066628   \n",
       "22                                      0.084821   \n",
       "23                                      2.068760   \n",
       "24                                      1.724780   \n",
       "25                                      1.248972   \n",
       "26                                      0.544297   \n",
       "27                                      1.797032   \n",
       "28                                      0.961905   \n",
       "29                                      0.209406   \n",
       "30                                      0.360661   \n",
       "...                                          ...   \n",
       "22686                                  14.017832   \n",
       "22687                                  15.946649   \n",
       "22688                                  16.235511   \n",
       "22689                                  16.223142   \n",
       "22690                                  16.326623   \n",
       "22691                                  16.292567   \n",
       "22692                                  15.802968   \n",
       "22693                                  14.352162   \n",
       "22694                                  13.837495   \n",
       "22695                                  13.725628   \n",
       "22696                                  13.306613   \n",
       "22697                                  12.415446   \n",
       "22698                                  12.263383   \n",
       "22699                                  12.412361   \n",
       "22700                                  12.084947   \n",
       "22701                                  11.635140   \n",
       "22702                                   2.454632   \n",
       "22703                                  -1.147427   \n",
       "22704                                  -1.074894   \n",
       "22705                                  -1.003475   \n",
       "22706                                  -0.874546   \n",
       "22707                                  -0.884588   \n",
       "22708                                  -0.870318   \n",
       "22709                                  -0.729136   \n",
       "22710                                  -0.527326   \n",
       "22711                                  -0.151767   \n",
       "22712                                   0.058366   \n",
       "22713                                  -0.255605   \n",
       "22714                                  -0.420624   \n",
       "22715                                  -0.388576   \n",
       "\n",
       "       value__kurtosis_p24_rougher.input.feed_pb  \\\n",
       "id                                                 \n",
       "1                                      -0.100395   \n",
       "2                                      -0.100395   \n",
       "3                                      -0.100395   \n",
       "4                                      -1.018959   \n",
       "5                                       0.735865   \n",
       "6                                      -1.741339   \n",
       "7                                      -1.019515   \n",
       "8                                      -0.865392   \n",
       "9                                      -0.687321   \n",
       "10                                     -0.609016   \n",
       "11                                     -0.530416   \n",
       "12                                     -0.399840   \n",
       "13                                     -0.108931   \n",
       "14                                      0.164841   \n",
       "15                                      0.200382   \n",
       "16                                      0.213566   \n",
       "17                                      0.030143   \n",
       "18                                     -0.121519   \n",
       "19                                     -0.153569   \n",
       "20                                     -0.226565   \n",
       "21                                     -0.194220   \n",
       "22                                     -0.355025   \n",
       "23                                     -0.251758   \n",
       "24                                     -0.451360   \n",
       "25                                      0.688735   \n",
       "26                                      0.288511   \n",
       "27                                      0.395032   \n",
       "28                                      0.731563   \n",
       "29                                      1.705130   \n",
       "30                                      2.828995   \n",
       "...                                          ...   \n",
       "22686                                   6.209861   \n",
       "22687                                   8.965590   \n",
       "22688                                   9.832458   \n",
       "22689                                   9.876717   \n",
       "22690                                  10.277431   \n",
       "22691                                  10.376757   \n",
       "22692                                   8.640978   \n",
       "22693                                   6.560167   \n",
       "22694                                   5.500908   \n",
       "22695                                   5.249413   \n",
       "22696                                   4.608710   \n",
       "22697                                   3.649199   \n",
       "22698                                   3.588046   \n",
       "22699                                   3.971896   \n",
       "22700                                   3.656061   \n",
       "22701                                   3.465072   \n",
       "22702                                  -0.512384   \n",
       "22703                                  -1.330729   \n",
       "22704                                  -1.307197   \n",
       "22705                                  -1.348273   \n",
       "22706                                  -1.203183   \n",
       "22707                                  -1.200770   \n",
       "22708                                  -1.066751   \n",
       "22709                                  -0.859243   \n",
       "22710                                  -0.468679   \n",
       "22711                                  -0.204353   \n",
       "22712                                  -0.217311   \n",
       "22713                                  -0.288732   \n",
       "22714                                  -0.020997   \n",
       "22715                                   0.129817   \n",
       "\n",
       "       value__kurtosis_p24_rougher.input.feed_rate  \\\n",
       "id                                                   \n",
       "1                                         0.641409   \n",
       "2                                         0.641409   \n",
       "3                                         0.641409   \n",
       "4                                         1.847391   \n",
       "5                                        -2.847330   \n",
       "6                                        -2.477429   \n",
       "7                                        -2.243768   \n",
       "8                                        -2.073712   \n",
       "9                                        -1.068359   \n",
       "10                                       -0.261467   \n",
       "11                                       -1.074190   \n",
       "12                                       -0.755824   \n",
       "13                                       -0.551383   \n",
       "14                                       -0.557110   \n",
       "15                                       -0.685415   \n",
       "16                                       -0.816604   \n",
       "17                                       -0.944128   \n",
       "18                                       -1.015449   \n",
       "19                                       -1.063458   \n",
       "20                                       -1.034818   \n",
       "21                                       -0.974105   \n",
       "22                                       -0.878931   \n",
       "23                                       -0.797134   \n",
       "24                                       -0.675700   \n",
       "25                                       -0.275476   \n",
       "26                                       -0.375225   \n",
       "27                                        0.268769   \n",
       "28                                        0.941433   \n",
       "29                                        1.862167   \n",
       "30                                        2.785834   \n",
       "...                                            ...   \n",
       "22686                                     4.449797   \n",
       "22687                                     5.108387   \n",
       "22688                                     5.261773   \n",
       "22689                                     5.275314   \n",
       "22690                                     5.357614   \n",
       "22691                                     5.712057   \n",
       "22692                                     5.904611   \n",
       "22693                                     5.862924   \n",
       "22694                                     5.478862   \n",
       "22695                                     5.285131   \n",
       "22696                                     5.124741   \n",
       "22697                                     5.129823   \n",
       "22698                                     5.832486   \n",
       "22699                                     5.714208   \n",
       "22700                                     5.675542   \n",
       "22701                                     5.515813   \n",
       "22702                                     5.238111   \n",
       "22703                                     5.117123   \n",
       "22704                                     5.138934   \n",
       "22705                                     5.931076   \n",
       "22706                                     3.484252   \n",
       "22707                                    -1.515005   \n",
       "22708                                    -1.436822   \n",
       "22709                                    -1.240629   \n",
       "22710                                    -0.988274   \n",
       "22711                                    -0.891043   \n",
       "22712                                    -0.895182   \n",
       "22713                                    -0.669110   \n",
       "22714                                     1.324657   \n",
       "22715                                     1.251465   \n",
       "\n",
       "       value__kurtosis_p24_rougher.input.feed_sol  \\\n",
       "id                                                  \n",
       "1                                        0.719380   \n",
       "2                                        0.719380   \n",
       "3                                        0.719380   \n",
       "4                                       -5.236670   \n",
       "5                                        0.963174   \n",
       "6                                        0.297311   \n",
       "7                                       -0.886157   \n",
       "8                                       -0.476416   \n",
       "9                                       -0.066269   \n",
       "10                                      -0.371682   \n",
       "11                                       1.062577   \n",
       "12                                      -0.144341   \n",
       "13                                      -0.590757   \n",
       "14                                      -0.678578   \n",
       "15                                      -0.707386   \n",
       "16                                      -0.940932   \n",
       "17                                      -1.155517   \n",
       "18                                      -1.196208   \n",
       "19                                      -1.353308   \n",
       "20                                      -1.448574   \n",
       "21                                      -1.469498   \n",
       "22                                      -1.443421   \n",
       "23                                      -1.461897   \n",
       "24                                      -1.471963   \n",
       "25                                      -1.457395   \n",
       "26                                      -1.226685   \n",
       "27                                      -0.931711   \n",
       "28                                      -0.648854   \n",
       "29                                      -0.404830   \n",
       "30                                       0.245761   \n",
       "...                                           ...   \n",
       "22686                                   15.208375   \n",
       "22687                                   15.495483   \n",
       "22688                                   16.088438   \n",
       "22689                                   16.302514   \n",
       "22690                                   16.469365   \n",
       "22691                                   16.472674   \n",
       "22692                                   16.468104   \n",
       "22693                                   17.087174   \n",
       "22694                                   17.274244   \n",
       "22695                                   17.472828   \n",
       "22696                                   17.725327   \n",
       "22697                                   17.655384   \n",
       "22698                                   17.605009   \n",
       "22699                                   17.623692   \n",
       "22700                                   17.610279   \n",
       "22701                                   17.669441   \n",
       "22702                                    9.187952   \n",
       "22703                                    0.836026   \n",
       "22704                                    1.055938   \n",
       "22705                                    0.886368   \n",
       "22706                                    2.064866   \n",
       "22707                                    0.412066   \n",
       "22708                                    0.035577   \n",
       "22709                                    0.070504   \n",
       "22710                                   -0.122482   \n",
       "22711                                    0.048443   \n",
       "22712                                   -0.086642   \n",
       "22713                                   -0.099929   \n",
       "22714                                   -0.067296   \n",
       "22715                                   -0.359026   \n",
       "\n",
       "       value__kurtosis_p24_rougher.input.feed_zn  ...  \\\n",
       "id                                                ...   \n",
       "1                                       0.000000  ...   \n",
       "2                                       0.000000  ...   \n",
       "3                                       0.000000  ...   \n",
       "4                                       1.551123  ...   \n",
       "5                                       1.352728  ...   \n",
       "6                                      -2.136735  ...   \n",
       "7                                      -1.669840  ...   \n",
       "8                                      -1.341732  ...   \n",
       "9                                      -1.008853  ...   \n",
       "10                                     -0.720809  ...   \n",
       "11                                     -0.514241  ...   \n",
       "12                                     -0.227099  ...   \n",
       "13                                     -0.061354  ...   \n",
       "14                                      0.169583  ...   \n",
       "15                                      0.430454  ...   \n",
       "16                                      0.638586  ...   \n",
       "17                                      0.812365  ...   \n",
       "18                                      0.918414  ...   \n",
       "19                                      1.189000  ...   \n",
       "20                                      1.314320  ...   \n",
       "21                                      1.199929  ...   \n",
       "22                                      1.009476  ...   \n",
       "23                                      1.208718  ...   \n",
       "24                                      0.523724  ...   \n",
       "25                                      1.154500  ...   \n",
       "26                                      0.345733  ...   \n",
       "27                                      0.109817  ...   \n",
       "28                                      0.122525  ...   \n",
       "29                                      0.857886  ...   \n",
       "30                                      1.925398  ...   \n",
       "...                                          ...  ...   \n",
       "22686                                  14.888988  ...   \n",
       "22687                                  16.546930  ...   \n",
       "22688                                  16.554054  ...   \n",
       "22689                                  16.709034  ...   \n",
       "22690                                  17.090635  ...   \n",
       "22691                                  17.284955  ...   \n",
       "22692                                  16.849824  ...   \n",
       "22693                                  15.418055  ...   \n",
       "22694                                  14.811784  ...   \n",
       "22695                                  14.595325  ...   \n",
       "22696                                  14.067102  ...   \n",
       "22697                                  12.950715  ...   \n",
       "22698                                  12.563069  ...   \n",
       "22699                                  12.620341  ...   \n",
       "22700                                  12.443171  ...   \n",
       "22701                                  11.955170  ...   \n",
       "22702                                   1.818604  ...   \n",
       "22703                                  -1.354387  ...   \n",
       "22704                                  -1.226713  ...   \n",
       "22705                                  -1.109894  ...   \n",
       "22706                                  -1.073845  ...   \n",
       "22707                                  -1.077137  ...   \n",
       "22708                                  -1.081658  ...   \n",
       "22709                                  -0.941472  ...   \n",
       "22710                                  -0.746260  ...   \n",
       "22711                                  -0.823593  ...   \n",
       "22712                                  -0.793588  ...   \n",
       "22713                                   0.123587  ...   \n",
       "22714                                   0.510753  ...   \n",
       "22715                                   0.229893  ...   \n",
       "\n",
       "       value__skewness_p24_primary_cleaner.state.floatbank8_a_air  \\\n",
       "id                                                                  \n",
       "1                                              -0.058141            \n",
       "2                                              -0.058141            \n",
       "3                                              -0.058006            \n",
       "4                                              -0.909072            \n",
       "5                                              -1.295466            \n",
       "6                                              -1.552102            \n",
       "7                                              -1.766990            \n",
       "8                                              -1.955110            \n",
       "9                                              -2.118285            \n",
       "10                                             -2.251644            \n",
       "11                                             -2.395041            \n",
       "12                                             -2.529739            \n",
       "13                                             -2.644929            \n",
       "14                                             -2.759338            \n",
       "15                                             -2.849141            \n",
       "16                                             -2.959333            \n",
       "17                                             -3.051241            \n",
       "18                                             -3.152495            \n",
       "19                                             -3.249987            \n",
       "20                                             -3.344240            \n",
       "21                                             -3.429237            \n",
       "22                                             -3.498380            \n",
       "23                                             -3.558007            \n",
       "24                                             -3.618187            \n",
       "25                                             -3.528227            \n",
       "26                                              0.045677            \n",
       "27                                              0.219101            \n",
       "28                                              0.320580            \n",
       "29                                              0.483096            \n",
       "30                                              0.623160            \n",
       "...                                                  ...            \n",
       "22686                                           0.175253            \n",
       "22687                                           0.266254            \n",
       "22688                                           0.356041            \n",
       "22689                                           0.442579            \n",
       "22690                                           0.521779            \n",
       "22691                                           0.585244            \n",
       "22692                                           0.614807            \n",
       "22693                                           0.567008            \n",
       "22694                                           0.377527            \n",
       "22695                                          -0.151888            \n",
       "22696                                          -0.196253            \n",
       "22697                                          -0.197970            \n",
       "22698                                          -0.231618            \n",
       "22699                                          -0.415757            \n",
       "22700                                          -0.609148            \n",
       "22701                                          -0.817447            \n",
       "22702                                          -1.048280            \n",
       "22703                                          -1.313032            \n",
       "22704                                          -1.630326            \n",
       "22705                                          -2.034105            \n",
       "22706                                          -2.595788            \n",
       "22707                                          -3.498935            \n",
       "22708                                          -4.879631            \n",
       "22709                                           4.887828            \n",
       "22710                                           4.882352            \n",
       "22711                                           4.874318            \n",
       "22712                                           4.863955            \n",
       "22713                                           3.560618            \n",
       "22714                                           2.768172            \n",
       "22715                                           2.166352            \n",
       "\n",
       "       value__skewness_p24_rougher.input.feed_fe  \\\n",
       "id                                                 \n",
       "1                                      -0.263996   \n",
       "2                                      -0.263996   \n",
       "3                                       1.237514   \n",
       "4                                      -0.366498   \n",
       "5                                       0.345700   \n",
       "6                                      -1.867800   \n",
       "7                                      -1.953136   \n",
       "8                                      -1.446646   \n",
       "9                                      -0.874414   \n",
       "10                                     -0.544432   \n",
       "11                                     -0.457193   \n",
       "12                                     -0.277472   \n",
       "13                                     -0.432711   \n",
       "14                                     -0.557710   \n",
       "15                                     -0.597167   \n",
       "16                                     -0.708668   \n",
       "17                                     -0.707093   \n",
       "18                                     -0.349228   \n",
       "19                                     -0.299126   \n",
       "20                                     -0.329588   \n",
       "21                                     -0.384867   \n",
       "22                                     -0.400543   \n",
       "23                                     -1.143724   \n",
       "24                                     -0.939013   \n",
       "25                                     -0.738803   \n",
       "26                                     -0.556122   \n",
       "27                                     -1.081037   \n",
       "28                                     -1.052660   \n",
       "29                                     -0.827511   \n",
       "30                                     -0.886010   \n",
       "...                                          ...   \n",
       "22686                                  -3.403333   \n",
       "22687                                  -3.807569   \n",
       "22688                                  -3.851237   \n",
       "22689                                  -3.848732   \n",
       "22690                                  -3.868224   \n",
       "22691                                  -3.868227   \n",
       "22692                                  -3.780891   \n",
       "22693                                  -3.495602   \n",
       "22694                                  -3.405969   \n",
       "22695                                  -3.390963   \n",
       "22696                                  -3.319952   \n",
       "22697                                  -3.156327   \n",
       "22698                                  -3.148351   \n",
       "22699                                  -3.192564   \n",
       "22700                                  -3.147672   \n",
       "22701                                  -3.075442   \n",
       "22702                                  -0.986669   \n",
       "22703                                   0.173827   \n",
       "22704                                   0.084209   \n",
       "22705                                   0.156532   \n",
       "22706                                   0.056451   \n",
       "22707                                   0.015073   \n",
       "22708                                  -0.102723   \n",
       "22709                                  -0.234905   \n",
       "22710                                  -0.413616   \n",
       "22711                                  -0.536726   \n",
       "22712                                  -0.428842   \n",
       "22713                                  -0.244130   \n",
       "22714                                  -0.161340   \n",
       "22715                                  -0.278169   \n",
       "\n",
       "       value__skewness_p24_rougher.input.feed_pb  \\\n",
       "id                                                 \n",
       "1                                      -0.259988   \n",
       "2                                      -0.259988   \n",
       "3                                      -1.581082   \n",
       "4                                      -0.868829   \n",
       "5                                      -1.141334   \n",
       "6                                      -0.379789   \n",
       "7                                      -0.499886   \n",
       "8                                      -0.644398   \n",
       "9                                      -0.616591   \n",
       "10                                     -0.594845   \n",
       "11                                     -0.450139   \n",
       "12                                     -0.611379   \n",
       "13                                     -0.698885   \n",
       "14                                     -0.801609   \n",
       "15                                     -0.865316   \n",
       "16                                     -0.535357   \n",
       "17                                     -0.483388   \n",
       "18                                     -0.445557   \n",
       "19                                     -0.526479   \n",
       "20                                     -0.431321   \n",
       "21                                     -0.221814   \n",
       "22                                     -0.231805   \n",
       "23                                     -0.291563   \n",
       "24                                     -0.311314   \n",
       "25                                     -0.816008   \n",
       "26                                     -0.702612   \n",
       "27                                     -0.752721   \n",
       "28                                     -0.881985   \n",
       "29                                     -1.112602   \n",
       "30                                     -1.378934   \n",
       "...                                          ...   \n",
       "22686                                  -1.280983   \n",
       "22687                                  -2.438809   \n",
       "22688                                  -2.599074   \n",
       "22689                                  -2.625165   \n",
       "22690                                  -2.725084   \n",
       "22691                                  -2.770523   \n",
       "22692                                  -2.350312   \n",
       "22693                                  -1.638019   \n",
       "22694                                  -1.468775   \n",
       "22695                                  -1.503685   \n",
       "22696                                  -1.429577   \n",
       "22697                                  -1.182631   \n",
       "22698                                  -1.268739   \n",
       "22699                                  -1.427592   \n",
       "22700                                  -1.423737   \n",
       "22701                                  -1.426690   \n",
       "22702                                  -0.246957   \n",
       "22703                                   0.011671   \n",
       "22704                                  -0.063747   \n",
       "22705                                   0.004272   \n",
       "22706                                  -0.106869   \n",
       "22707                                  -0.120907   \n",
       "22708                                  -0.258309   \n",
       "22709                                  -0.376417   \n",
       "22710                                  -0.511321   \n",
       "22711                                  -0.536540   \n",
       "22712                                  -0.402503   \n",
       "22713                                  -0.368462   \n",
       "22714                                  -0.489077   \n",
       "22715                                  -0.692602   \n",
       "\n",
       "       value__skewness_p24_rougher.input.feed_rate  \\\n",
       "id                                                   \n",
       "1                                        -0.860201   \n",
       "2                                        -0.860201   \n",
       "3                                         1.219928   \n",
       "4                                         1.447526   \n",
       "5                                         0.333572   \n",
       "6                                        -0.038194   \n",
       "7                                         0.311307   \n",
       "8                                         0.111052   \n",
       "9                                         0.333733   \n",
       "10                                        0.649717   \n",
       "11                                        0.371232   \n",
       "12                                        0.501918   \n",
       "13                                        0.479758   \n",
       "14                                        0.353307   \n",
       "15                                        0.194165   \n",
       "16                                        0.043818   \n",
       "17                                       -0.084534   \n",
       "18                                       -0.193787   \n",
       "19                                       -0.260003   \n",
       "20                                       -0.356931   \n",
       "21                                       -0.445986   \n",
       "22                                       -0.525052   \n",
       "23                                       -0.601800   \n",
       "24                                       -0.663494   \n",
       "25                                       -0.807595   \n",
       "26                                       -0.750209   \n",
       "27                                       -0.935843   \n",
       "28                                       -1.168332   \n",
       "29                                       -1.392952   \n",
       "30                                       -1.628029   \n",
       "...                                            ...   \n",
       "22686                                    -2.009262   \n",
       "22687                                    -2.181580   \n",
       "22688                                    -2.238406   \n",
       "22689                                    -2.241248   \n",
       "22690                                    -2.262235   \n",
       "22691                                    -2.366445   \n",
       "22692                                    -2.408684   \n",
       "22693                                    -2.399009   \n",
       "22694                                    -2.291341   \n",
       "22695                                    -2.225140   \n",
       "22696                                    -2.165712   \n",
       "22697                                    -2.166860   \n",
       "22698                                    -2.291696   \n",
       "22699                                    -2.246287   \n",
       "22700                                    -2.213072   \n",
       "22701                                    -2.146464   \n",
       "22702                                    -2.048024   \n",
       "22703                                    -1.979828   \n",
       "22704                                    -1.941957   \n",
       "22705                                    -2.131994   \n",
       "22706                                    -1.292190   \n",
       "22707                                     0.190363   \n",
       "22708                                     0.244128   \n",
       "22709                                     0.314706   \n",
       "22710                                     0.393914   \n",
       "22711                                     0.404000   \n",
       "22712                                     0.408772   \n",
       "22713                                     0.508279   \n",
       "22714                                     1.096337   \n",
       "22715                                     1.256587   \n",
       "\n",
       "       value__skewness_p24_rougher.input.feed_sol  \\\n",
       "id                                                  \n",
       "1                                       -0.837851   \n",
       "2                                       -0.837851   \n",
       "3                                        1.437744   \n",
       "4                                       -0.118080   \n",
       "5                                       -1.059807   \n",
       "6                                       -0.652324   \n",
       "7                                       -0.153746   \n",
       "8                                       -0.346535   \n",
       "9                                       -0.344318   \n",
       "10                                      -0.408715   \n",
       "11                                       0.619870   \n",
       "12                                       0.484257   \n",
       "13                                       0.260449   \n",
       "14                                       0.337844   \n",
       "15                                       0.408523   \n",
       "16                                       0.365021   \n",
       "17                                       0.285857   \n",
       "18                                       0.268521   \n",
       "19                                       0.141201   \n",
       "20                                       0.045700   \n",
       "21                                      -0.004671   \n",
       "22                                      -0.025464   \n",
       "23                                      -0.079103   \n",
       "24                                      -0.134794   \n",
       "25                                      -0.284315   \n",
       "26                                      -0.452733   \n",
       "27                                      -0.648499   \n",
       "28                                      -0.831709   \n",
       "29                                      -0.930877   \n",
       "30                                      -1.120028   \n",
       "...                                           ...   \n",
       "22686                                   -3.634528   \n",
       "22687                                   -3.691705   \n",
       "22688                                   -3.792503   \n",
       "22689                                   -3.831909   \n",
       "22690                                   -3.864071   \n",
       "22691                                   -3.863483   \n",
       "22692                                   -3.862380   \n",
       "22693                                   -3.967179   \n",
       "22694                                   -3.995980   \n",
       "22695                                   -4.026524   \n",
       "22696                                   -4.066097   \n",
       "22697                                   -4.049845   \n",
       "22698                                   -4.039331   \n",
       "22699                                   -4.039112   \n",
       "22700                                   -4.036134   \n",
       "22701                                   -4.043260   \n",
       "22702                                   -2.624308   \n",
       "22703                                   -0.791803   \n",
       "22704                                   -0.933113   \n",
       "22705                                   -0.851820   \n",
       "22706                                   -1.030039   \n",
       "22707                                   -0.360570   \n",
       "22708                                   -0.451085   \n",
       "22709                                   -0.699720   \n",
       "22710                                   -0.646414   \n",
       "22711                                   -0.313647   \n",
       "22712                                   -0.078217   \n",
       "22713                                   -0.104775   \n",
       "22714                                   -0.082733   \n",
       "22715                                   -0.117435   \n",
       "\n",
       "       value__skewness_p24_rougher.input.feed_zn  \\\n",
       "id                                                 \n",
       "1                                      -0.323986   \n",
       "2                                      -0.323986   \n",
       "3                                      -1.708960   \n",
       "4                                      -1.423029   \n",
       "5                                      -1.380184   \n",
       "6                                      -0.519982   \n",
       "7                                      -0.365018   \n",
       "8                                      -0.631005   \n",
       "9                                      -0.791393   \n",
       "10                                     -0.837967   \n",
       "11                                     -0.788417   \n",
       "12                                     -0.935379   \n",
       "13                                     -1.001661   \n",
       "14                                     -1.105226   \n",
       "15                                     -1.208510   \n",
       "16                                     -1.279943   \n",
       "17                                     -1.327928   \n",
       "18                                     -1.329519   \n",
       "19                                     -1.413357   \n",
       "20                                     -1.437748   \n",
       "21                                     -1.091163   \n",
       "22                                     -0.873989   \n",
       "23                                     -0.918574   \n",
       "24                                     -0.876548   \n",
       "25                                     -1.159079   \n",
       "26                                     -0.949097   \n",
       "27                                     -0.855931   \n",
       "28                                     -0.860288   \n",
       "29                                     -1.038948   \n",
       "30                                     -1.286744   \n",
       "...                                          ...   \n",
       "22686                                  -3.546164   \n",
       "22687                                  -3.876215   \n",
       "22688                                  -3.872116   \n",
       "22689                                  -3.898826   \n",
       "22690                                  -3.962066   \n",
       "22691                                  -3.999136   \n",
       "22692                                  -3.927406   \n",
       "22693                                  -3.654907   \n",
       "22694                                  -3.553496   \n",
       "22695                                  -3.523752   \n",
       "22696                                  -3.437032   \n",
       "22697                                  -3.224690   \n",
       "22698                                  -3.168623   \n",
       "22699                                  -3.191450   \n",
       "22700                                  -3.176837   \n",
       "22701                                  -3.102448   \n",
       "22702                                  -0.892490   \n",
       "22703                                   0.063209   \n",
       "22704                                  -0.065354   \n",
       "22705                                  -0.051745   \n",
       "22706                                  -0.075057   \n",
       "22707                                  -0.024562   \n",
       "22708                                  -0.022400   \n",
       "22709                                  -0.024542   \n",
       "22710                                  -0.058314   \n",
       "22711                                  -0.072308   \n",
       "22712                                  -0.095619   \n",
       "22713                                  -0.493448   \n",
       "22714                                  -0.782838   \n",
       "22715                                  -0.870948   \n",
       "\n",
       "       value__skewness_p24_rougher.input.floatbank10_copper_sulfate  \\\n",
       "id                                                                    \n",
       "1                                              -0.252958              \n",
       "2                                              -0.252958              \n",
       "3                                              -1.351549              \n",
       "4                                              -1.836277              \n",
       "5                                              -1.708991              \n",
       "6                                              -0.706237              \n",
       "7                                              -0.643948              \n",
       "8                                               0.001970              \n",
       "9                                               0.598911              \n",
       "10                                              0.752999              \n",
       "11                                              0.636061              \n",
       "12                                              0.437370              \n",
       "13                                              0.219953              \n",
       "14                                              0.042417              \n",
       "15                                             -0.109274              \n",
       "16                                             -0.231819              \n",
       "17                                             -0.136040              \n",
       "18                                             -0.114026              \n",
       "19                                             -0.193868              \n",
       "20                                             -0.260680              \n",
       "21                                             -0.242694              \n",
       "22                                             -0.244774              \n",
       "23                                             -0.327956              \n",
       "24                                             -0.241043              \n",
       "25                                             -0.245985              \n",
       "26                                             -0.259612              \n",
       "27                                             -0.370402              \n",
       "28                                             -0.487594              \n",
       "29                                             -0.548283              \n",
       "30                                             -0.551626              \n",
       "...                                                  ...              \n",
       "22686                                          -0.786787              \n",
       "22687                                          -0.800738              \n",
       "22688                                          -0.925188              \n",
       "22689                                          -1.078631              \n",
       "22690                                          -1.157073              \n",
       "22691                                          -1.180168              \n",
       "22692                                          -1.190211              \n",
       "22693                                          -1.206616              \n",
       "22694                                          -1.531869              \n",
       "22695                                          -1.659311              \n",
       "22696                                          -1.643544              \n",
       "22697                                          -1.651317              \n",
       "22698                                          -1.684580              \n",
       "22699                                          -1.725410              \n",
       "22700                                          -1.839363              \n",
       "22701                                          -1.909829              \n",
       "22702                                          -1.940938              \n",
       "22703                                          -1.983548              \n",
       "22704                                          -1.990903              \n",
       "22705                                          -1.870168              \n",
       "22706                                          -2.297273              \n",
       "22707                                          -0.348878              \n",
       "22708                                          -0.123327              \n",
       "22709                                          -0.164571              \n",
       "22710                                          -0.015063              \n",
       "22711                                          -0.064728              \n",
       "22712                                          -0.039393              \n",
       "22713                                          -0.056668              \n",
       "22714                                           0.112227              \n",
       "22715                                           0.115846              \n",
       "\n",
       "       value__skewness_p24_rougher.input.floatbank11_xanthate  \\\n",
       "id                                                              \n",
       "1                                              -0.368861        \n",
       "2                                              -0.368861        \n",
       "3                                               1.725034        \n",
       "4                                               0.001344        \n",
       "5                                              -0.605228        \n",
       "6                                              -0.964531        \n",
       "7                                              -1.226172        \n",
       "8                                               2.109900        \n",
       "9                                               1.285839        \n",
       "10                                              0.808516        \n",
       "11                                              0.484025        \n",
       "12                                              0.240944        \n",
       "13                                              0.053378        \n",
       "14                                             -0.104321        \n",
       "15                                             -0.241377        \n",
       "16                                             -0.356847        \n",
       "17                                             -0.432845        \n",
       "18                                             -0.506152        \n",
       "19                                             -0.580362        \n",
       "20                                             -0.555578        \n",
       "21                                             -0.494596        \n",
       "22                                             -0.357249        \n",
       "23                                             -0.305635        \n",
       "24                                             -0.318792        \n",
       "25                                             -0.432910        \n",
       "26                                             -0.501432        \n",
       "27                                             -0.667771        \n",
       "28                                             -0.786585        \n",
       "29                                             -0.840721        \n",
       "30                                             -0.667371        \n",
       "...                                                  ...        \n",
       "22686                                          -1.811834        \n",
       "22687                                          -1.999890        \n",
       "22688                                          -2.224131        \n",
       "22689                                          -2.475394        \n",
       "22690                                          -2.473122        \n",
       "22691                                          -2.472614        \n",
       "22692                                          -2.472933        \n",
       "22693                                          -2.506979        \n",
       "22694                                          -2.544535        \n",
       "22695                                          -2.618114        \n",
       "22696                                          -2.870043        \n",
       "22697                                          -2.887603        \n",
       "22698                                          -2.886208        \n",
       "22699                                          -2.886208        \n",
       "22700                                          -3.232049        \n",
       "22701                                          -3.190895        \n",
       "22702                                          -2.941106        \n",
       "22703                                          -2.402737        \n",
       "22704                                          -1.974486        \n",
       "22705                                          -1.597831        \n",
       "22706                                          -1.758908        \n",
       "22707                                          -1.751814        \n",
       "22708                                          -1.651485        \n",
       "22709                                          -1.650969        \n",
       "22710                                          -1.651134        \n",
       "22711                                          -1.650555        \n",
       "22712                                          -1.650902        \n",
       "22713                                          -1.650364        \n",
       "22714                                          -1.650802        \n",
       "22715                                          -1.650756        \n",
       "\n",
       "       value__skewness_p24_rougher.state.floatbank10_b_air  \\\n",
       "id                                                           \n",
       "1                                              -0.033020     \n",
       "2                                              -0.033020     \n",
       "3                                               0.664107     \n",
       "4                                               1.243404     \n",
       "5                                               1.521760     \n",
       "6                                               1.260495     \n",
       "7                                               1.283002     \n",
       "8                                               0.940207     \n",
       "9                                               1.133190     \n",
       "10                                              1.140621     \n",
       "11                                              1.268390     \n",
       "12                                              1.376548     \n",
       "13                                              1.478157     \n",
       "14                                              1.587134     \n",
       "15                                              1.500761     \n",
       "16                                              1.596267     \n",
       "17                                              1.513689     \n",
       "18                                              1.585030     \n",
       "19                                              1.589391     \n",
       "20                                              1.504301     \n",
       "21                                              1.491553     \n",
       "22                                              1.478397     \n",
       "23                                              1.547092     \n",
       "24                                              1.473735     \n",
       "25                                             -0.338378     \n",
       "26                                             -0.076968     \n",
       "27                                             -0.226741     \n",
       "28                                             -0.297322     \n",
       "29                                             -0.197756     \n",
       "30                                             -0.156639     \n",
       "...                                                  ...     \n",
       "22686                                          -0.153559     \n",
       "22687                                          -0.104158     \n",
       "22688                                          -0.131669     \n",
       "22689                                          -0.226151     \n",
       "22690                                          -0.370265     \n",
       "22691                                          -0.254252     \n",
       "22692                                          -0.346023     \n",
       "22693                                          -0.406844     \n",
       "22694                                          -0.259078     \n",
       "22695                                          -0.318330     \n",
       "22696                                          -0.447909     \n",
       "22697                                          -0.549385     \n",
       "22698                                          -0.522542     \n",
       "22699                                          -0.517308     \n",
       "22700                                          -0.570115     \n",
       "22701                                          -0.433502     \n",
       "22702                                          -0.405984     \n",
       "22703                                          -0.537429     \n",
       "22704                                          -0.539636     \n",
       "22705                                          -0.457935     \n",
       "22706                                          -1.012429     \n",
       "22707                                          -1.047206     \n",
       "22708                                          -0.345806     \n",
       "22709                                          -0.496049     \n",
       "22710                                          -0.422899     \n",
       "22711                                          -0.499954     \n",
       "22712                                          -0.438673     \n",
       "22713                                          -0.208201     \n",
       "22714                                          -0.088848     \n",
       "22715                                          -0.169631     \n",
       "\n",
       "       value__skewness_p24_secondary_cleaner.state.floatbank5_a_air  \n",
       "id                                                                   \n",
       "1                                              -0.038588             \n",
       "2                                              -0.038588             \n",
       "3                                              -1.403274             \n",
       "4                                              -0.188030             \n",
       "5                                               0.430250             \n",
       "6                                              -0.130560             \n",
       "7                                              -0.189063             \n",
       "8                                              -0.244638             \n",
       "9                                              -0.482942             \n",
       "10                                             -0.345575             \n",
       "11                                             -0.529503             \n",
       "12                                             -0.660087             \n",
       "13                                             -0.566638             \n",
       "14                                             -0.617217             \n",
       "15                                             -0.512268             \n",
       "16                                             -0.625535             \n",
       "17                                             -0.706220             \n",
       "18                                             -0.789007             \n",
       "19                                             -0.874524             \n",
       "20                                             -0.956758             \n",
       "21                                             -0.938923             \n",
       "22                                             -0.996041             \n",
       "23                                             -0.959424             \n",
       "24                                             -0.989114             \n",
       "25                                             -1.237850             \n",
       "26                                             -1.218004             \n",
       "27                                             -1.383096             \n",
       "28                                             -1.454488             \n",
       "29                                             -1.325225             \n",
       "30                                             -0.988746             \n",
       "...                                                  ...             \n",
       "22686                                           0.151219             \n",
       "22687                                           0.332312             \n",
       "22688                                           0.519651             \n",
       "22689                                           0.719381             \n",
       "22690                                           0.937403             \n",
       "22691                                           1.181987             \n",
       "22692                                           1.470814             \n",
       "22693                                           1.826080             \n",
       "22694                                           2.278574             \n",
       "22695                                           2.904465             \n",
       "22696                                           3.405399             \n",
       "22697                                           4.610704             \n",
       "22698                                          -0.009403             \n",
       "22699                                           0.105907             \n",
       "22700                                           0.045203             \n",
       "22701                                           0.035741             \n",
       "22702                                           0.123855             \n",
       "22703                                           0.186096             \n",
       "22704                                           0.206912             \n",
       "22705                                           0.152530             \n",
       "22706                                           0.722837             \n",
       "22707                                           0.695911             \n",
       "22708                                           4.638382             \n",
       "22709                                           3.504189             \n",
       "22710                                           3.504909             \n",
       "22711                                           3.505069             \n",
       "22712                                           3.508671             \n",
       "22713                                           2.823914             \n",
       "22714                                           2.394611             \n",
       "22715                                           1.937874             \n",
       "\n",
       "[22715 rows x 84 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root='..'\n",
    "df_flats = []\n",
    "for p in [36,6,24]:\n",
    "    df_tsfresh = pd.read_pickle(f'{root}/data/processed/train_test_tsfresh_{p}.pkl').reset_index(level=0)\n",
    "    tmp =df_tsfresh.pivot_table(index='id', columns=['level_0'])\n",
    "    tmp.columns = ['_'.join(col).strip() for col in tmp.columns.values]\n",
    "    df_flats.append(tmp)\n",
    "\n",
    "df_flat = pd.concat(df_flats,axis=1)\n",
    "\n",
    "df_flat.index.names = ['date']\n",
    "df_flat.head()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_cleaner.input.copper_sulfate</th>\n",
       "      <th>primary_cleaner.input.depressant</th>\n",
       "      <th>primary_cleaner.input.feed_size</th>\n",
       "      <th>primary_cleaner.input.xanthate</th>\n",
       "      <th>primary_cleaner.state.floatbank8_a_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_a_level</th>\n",
       "      <th>primary_cleaner.state.floatbank8_b_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_b_level</th>\n",
       "      <th>primary_cleaner.state.floatbank8_c_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_c_level</th>\n",
       "      <th>...</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [primary_cleaner.input.copper_sulfate, primary_cleaner.input.depressant, primary_cleaner.input.feed_size, primary_cleaner.input.xanthate, primary_cleaner.state.floatbank8_a_air, primary_cleaner.state.floatbank8_a_level, primary_cleaner.state.floatbank8_b_air, primary_cleaner.state.floatbank8_b_level, primary_cleaner.state.floatbank8_c_air, primary_cleaner.state.floatbank8_c_level, primary_cleaner.state.floatbank8_d_air, primary_cleaner.state.floatbank8_d_level, rougher.input.feed_fe, rougher.input.feed_pb, rougher.input.feed_rate, rougher.input.feed_size, rougher.input.feed_sol, rougher.input.feed_zn, rougher.input.floatbank10_copper_sulfate, rougher.input.floatbank10_xanthate, rougher.input.floatbank11_copper_sulfate, rougher.input.floatbank11_xanthate, rougher.state.floatbank10_a_air, rougher.state.floatbank10_a_level, rougher.state.floatbank10_b_air, rougher.state.floatbank10_b_level, rougher.state.floatbank10_c_air, rougher.state.floatbank10_c_level, rougher.state.floatbank10_d_air, rougher.state.floatbank10_d_level, rougher.state.floatbank10_e_air, rougher.state.floatbank10_e_level, rougher.state.floatbank10_f_air, rougher.state.floatbank10_f_level, secondary_cleaner.state.floatbank2_a_air, secondary_cleaner.state.floatbank2_a_level, secondary_cleaner.state.floatbank2_b_air, secondary_cleaner.state.floatbank2_b_level, secondary_cleaner.state.floatbank3_a_air, secondary_cleaner.state.floatbank3_a_level, secondary_cleaner.state.floatbank3_b_air, secondary_cleaner.state.floatbank3_b_level, secondary_cleaner.state.floatbank4_a_air, secondary_cleaner.state.floatbank4_a_level, secondary_cleaner.state.floatbank4_b_air, secondary_cleaner.state.floatbank4_b_level, secondary_cleaner.state.floatbank5_a_air, secondary_cleaner.state.floatbank5_a_level, secondary_cleaner.state.floatbank5_b_air, secondary_cleaner.state.floatbank5_b_level, secondary_cleaner.state.floatbank6_a_air, secondary_cleaner.state.floatbank6_a_level, day, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 305 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2016\n",
    "tgt = 'final.output.recovery'\n",
    "X = data_dict[year]['X_train_ts']\n",
    "y = data_dict[year]['y_train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test shape: (2928, 53), train: (0, 305)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [DatetimeIndex(['2016-01-15 00:00:00+00:00', '2016-01-15 01:00:00+00:00',\\n               '2016-01-15 02:00:00+00:00', '2016-01-15 03:00:00+00:00',\\n               '2016-01-15 04:00:00+00:00', '2016-01-15 05:00:00+00:00',\\n               '2016-01-15 06:00:00+00:00', '2016-01-15 07:00:00+00:00',\\n               '2016-01-15 08:00:00+00:00', '2016-01-15 09:00:00+00:00',\\n               ...\\n               '2016-08-31 14:59:59+00:00', '2016-08-31 15:59:59+00:00',\\n               '2016-08-31 16:59:59+00:00', '2016-08-31 17:59:59+00:00',\\n               '2016-08-31 18:59:59+00:00', '2016-08-31 19:59:59+00:00',\\n               '2016-08-31 20:59:59+00:00', '2016-08-31 21:59:59+00:00',\\n               '2016-08-31 22:59:59+00:00', '2016-08-31 23:59:59+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=4902, freq=None)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-34881d1dbef9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0minds_common\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minds_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds_common\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minds_common\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    875\u001b[0m         \u001b[1;31m# ugly hack for GH #836\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multi_take_opportunity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;31m# no shortcut needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_multi_take\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         d = {axis: self._get_listlike_indexer(key, axis)\n\u001b[1;32m--> 934\u001b[1;33m              for (key, axis) in zip(tup, o._AXIS_ORDERS)}\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_with_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         d = {axis: self._get_listlike_indexer(key, axis)\n\u001b[1;32m--> 934\u001b[1;33m              for (key, axis) in zip(tup, o._AXIS_ORDERS)}\n\u001b[0m\u001b[0;32m    935\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_with_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [DatetimeIndex(['2016-01-15 00:00:00+00:00', '2016-01-15 01:00:00+00:00',\\n               '2016-01-15 02:00:00+00:00', '2016-01-15 03:00:00+00:00',\\n               '2016-01-15 04:00:00+00:00', '2016-01-15 05:00:00+00:00',\\n               '2016-01-15 06:00:00+00:00', '2016-01-15 07:00:00+00:00',\\n               '2016-01-15 08:00:00+00:00', '2016-01-15 09:00:00+00:00',\\n               ...\\n               '2016-08-31 14:59:59+00:00', '2016-08-31 15:59:59+00:00',\\n               '2016-08-31 16:59:59+00:00', '2016-08-31 17:59:59+00:00',\\n               '2016-08-31 18:59:59+00:00', '2016-08-31 19:59:59+00:00',\\n               '2016-08-31 20:59:59+00:00', '2016-08-31 21:59:59+00:00',\\n               '2016-08-31 22:59:59+00:00', '2016-08-31 23:59:59+00:00'],\\n              dtype='datetime64[ns, UTC]', name='date', length=4902, freq=None)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "X_test=  data_dict[year]['X_test']\n",
    "\n",
    "print(f'1) Test shape: {X_test.shape}, train: {X.shape}')\n",
    "    \n",
    "inds_y = y[(y[tgt] > 5) & (y[tgt] < 100)].index\n",
    "inds_common = inds_y\n",
    "\n",
    "X = X.loc[inds_common,]\n",
    "y = y.loc[inds_common, tgt]\n",
    "\n",
    "X = X.sample(frac=0.3,random_state=123).sort_index().dropna()\n",
    "y= y[X.index]\n",
    "\n",
    "\n",
    "\n",
    "Nmonths_total = 8\n",
    "Nspl = int(Nmonths_total * 30 / 15)\n",
    "Nmonths_test = 4\n",
    "Nmonths_min_train = 2.5\n",
    "train_splits = Nspl // Nmonths_total*Nmonths_min_train\n",
    "test_splits=int(Nmonths_test / Nmonths_total*Nspl)\n",
    "cv = TimeSeriesSplitImproved(n_splits=Nspl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_cleaner.input.copper_sulfate</th>\n",
       "      <th>primary_cleaner.input.depressant</th>\n",
       "      <th>primary_cleaner.input.feed_size</th>\n",
       "      <th>primary_cleaner.input.xanthate</th>\n",
       "      <th>primary_cleaner.state.floatbank8_a_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_a_level</th>\n",
       "      <th>primary_cleaner.state.floatbank8_b_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_b_level</th>\n",
       "      <th>primary_cleaner.state.floatbank8_c_air</th>\n",
       "      <th>primary_cleaner.state.floatbank8_c_level</th>\n",
       "      <th>...</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r</th>\n",
       "      <th>v_a_l_u_e_____s_k_e_w_n_e_s_s___p_2_4___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [primary_cleaner.input.copper_sulfate, primary_cleaner.input.depressant, primary_cleaner.input.feed_size, primary_cleaner.input.xanthate, primary_cleaner.state.floatbank8_a_air, primary_cleaner.state.floatbank8_a_level, primary_cleaner.state.floatbank8_b_air, primary_cleaner.state.floatbank8_b_level, primary_cleaner.state.floatbank8_c_air, primary_cleaner.state.floatbank8_c_level, primary_cleaner.state.floatbank8_d_air, primary_cleaner.state.floatbank8_d_level, rougher.input.feed_fe, rougher.input.feed_pb, rougher.input.feed_rate, rougher.input.feed_size, rougher.input.feed_sol, rougher.input.feed_zn, rougher.input.floatbank10_copper_sulfate, rougher.input.floatbank10_xanthate, rougher.input.floatbank11_copper_sulfate, rougher.input.floatbank11_xanthate, rougher.state.floatbank10_a_air, rougher.state.floatbank10_a_level, rougher.state.floatbank10_b_air, rougher.state.floatbank10_b_level, rougher.state.floatbank10_c_air, rougher.state.floatbank10_c_level, rougher.state.floatbank10_d_air, rougher.state.floatbank10_d_level, rougher.state.floatbank10_e_air, rougher.state.floatbank10_e_level, rougher.state.floatbank10_f_air, rougher.state.floatbank10_f_level, secondary_cleaner.state.floatbank2_a_air, secondary_cleaner.state.floatbank2_a_level, secondary_cleaner.state.floatbank2_b_air, secondary_cleaner.state.floatbank2_b_level, secondary_cleaner.state.floatbank3_a_air, secondary_cleaner.state.floatbank3_a_level, secondary_cleaner.state.floatbank3_b_air, secondary_cleaner.state.floatbank3_b_level, secondary_cleaner.state.floatbank4_a_air, secondary_cleaner.state.floatbank4_a_level, secondary_cleaner.state.floatbank4_b_air, secondary_cleaner.state.floatbank4_b_level, secondary_cleaner.state.floatbank5_a_air, secondary_cleaner.state.floatbank5_a_level, secondary_cleaner.state.floatbank5_b_air, secondary_cleaner.state.floatbank5_b_level, secondary_cleaner.state.floatbank6_a_air, secondary_cleaner.state.floatbank6_a_level, day, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____k_u_r_t_o_s_i_s___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_i_n_t_e_r_c_e_p_t_\"___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___f_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___p_b, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___r_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___s_o_l, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_e_e_d___z_n, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_0___c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._i_n_p_u_t_._f_l_o_a_t_b_a_n_k_1_1___x_a_n_t_h_a_t_e, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___r_o_u_g_h_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_1_0___b___a_i_r, v_a_l_u_e_____l_i_n_e_a_r___t_r_e_n_d_____a_t_t_r___\"_s_l_o_p_e_\"___p_3_6___s_e_c_o_n_d_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_5___a___a_i_r, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._c_o_p_p_e_r___s_u_l_f_a_t_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._d_e_p_r_e_s_s_a_n_t, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._f_e_e_d___s_i_z_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._i_n_p_u_t_._x_a_n_t_h_a_t_e, v_a_l_u_e_____q_u_a_n_t_i_l_e_____q___0_._0_1___p_3_6___p_r_i_m_a_r_y___c_l_e_a_n_e_r_._s_t_a_t_e_._f_l_o_a_t_b_a_n_k_8___a___a_i_r, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 305 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.005, random_state=1))\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "CatBoost = CatBoostRegressor(loss_function='MAE',random_seed =123,learning_rate=0.1,max_depth=8,task_type='GPU',od_type = 'Iter',od_wait= 15,iterations = 2000)\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.15, max_depth=12, \n",
    "                             n_estimators=500,\n",
    "                             reg_alpha=0.4, reg_lambda=0.8,\n",
    "                             subsample=0.5, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='mae',num_leaves=5,\n",
    "                              learning_rate=0.15, n_estimators=500,\n",
    "                              bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9  )\n",
    "param_grids = {'n_estimators': 1000,\n",
    "                   'max_features': 0.8, # tuned\n",
    "                   'max_depth': 14, # tuned\n",
    "                   }\n",
    "model_qrf = RandomForestQuantileRegressor(**param_grids,\n",
    "               criterion = 'mae',\n",
    "               n_jobs = -1,\n",
    "                random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model,cv = None):\n",
    "    if cv is None:\n",
    "        cv = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n",
    "    score  = make_scorer(mase,greater_is_better=False)\n",
    "    #rmse= np.sqrt(-cross_val_score(model, X.values, y.values.reshape(-1,1), scoring=score, cv = cv))\n",
    "    rmse= cross_val_score(model, X.values, y.values.reshape(-1,), scoring=score, cv = cv)\n",
    "    \n",
    "    return(rmse)\n",
    "\n",
    "def rmsle_cv_boxcox_tgt(model,cv = None,lam = 4.321):\n",
    "    from scipy.stats import boxcox\n",
    "    from scipy.special import inv_boxcox\n",
    "    if cv is None:\n",
    "        cv = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X.values)\n",
    "    scores = []\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X,fixed_length=False, train_splits=train_splits, test_splits=test_splits)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        y_train = boxcox(y_train,lam)\n",
    "        model.fit(X_train,y_train)\n",
    "        preds  = inv_boxcox(model.predict(X_valid),4.321)\n",
    "        score_val = mase(preds,y_valid)\n",
    "        # print(f'Fold {fold_n}. Score: {score_val:.4f}.')\n",
    "        print('')\n",
    "        scores.append(score_val)\n",
    "    \n",
    "    #print(f'CV mean score: {np.mean(scores):.4f}, std: {np.std(scores):.4f}.')\n",
    "    \n",
    "    return(np.array(scores))\n",
    "\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: -3.1228 (0.3227)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: -2.9564 (0.4491)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso,cv = cv)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: -3.1416 (0.3207)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: -2.9653 (0.4515)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet,cv=cv)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(ENet,cv=None)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-97d2f4eaf0ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGBoost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient Boosting score: {:.4f} ({:.4f})\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGBoost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gradient Boosting score: {:.4f} ({:.4f})\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-8443ffb2578e>\u001b[0m in \u001b[0;36mrmsle_cv\u001b[1;34m(model, cv)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mscore\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreater_is_better\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#rmse= np.sqrt(-cross_val_score(model, X.values, y.values.reshape(-1,1), scoring=score, cv = cv))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrmse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[0;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             residual = loss.negative_gradient(y, y_pred, k=k,\n\u001b[1;32m-> 1171\u001b[1;33m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m             \u001b[1;31m# induce regression tree on residuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[1;34m(self, y, pred, sample_weight, **kargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_weighted_percentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mgamma_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\utils\\stats.py\u001b[0m in \u001b[0;36m_weighted_percentile\u001b[1;34m(array, sample_weight, percentile)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mCompute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0marray\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msorted_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Find index of median prediction for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m     \"\"\"\n\u001b[1;32m--> 973\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argsort'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost,cv=cv)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: -2.5367 (0.2999)\n",
      "\n",
      "Xgboost score: -2.1219 (0.1754)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb,cv=cv)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: -3.5367 (0.2241)\n",
      "\n",
      "LGBM score: -3.0009 (0.2294)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb,cv=cv)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: -3.4970 (0.6479)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-7dd7d16a87d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_qrf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LGBM score: {:.4f} ({:.4f})\\n\"\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_qrf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LGBM score: {:.4f} ({:.4f})\\n\"\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-98-2529c7ccdca9>\u001b[0m in \u001b[0;36mrmsle_cv\u001b[1;34m(model, cv)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mscore\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreater_is_better\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#rmse= np.sqrt(-cross_val_score(model, X.values, y.values.reshape(-1,1), scoring=score, cv = cv))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrmse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\skgarden\\quantile\\ensemble.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     78\u001b[0m         X, y = check_X_y(\n\u001b[0;32m     79\u001b[0m             X, y, accept_sparse=\"csc\", dtype=np.float32, multi_output=False)\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseForestQuantileRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_qrf,cv=cv)\n",
    "print(\"QRFscore: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_qrf)\n",
    "print(\"QRF score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6c328ec251b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[1;34m\"od_wait\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m           }\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#print(\"Catboostmodels score: {:.4f} ({:.4f})\".format(scores.mean(), scores.std()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, max_time_spent_on_fixed_cost_ratio, dev_max_iterations_batch_size)\u001b[0m\n\u001b[0;32m   2949\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2950\u001b[0m         return _cv(params, pool, fold_count, inverted, partition_random_seed, shuffle, stratified,\n\u001b[1;32m-> 2951\u001b[1;33m                    as_pandas, max_time_spent_on_fixed_cost_ratio, dev_max_iterations_batch_size)\n\u001b[0m\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool = Pool(X, y)\n",
    "params = {'iterations': 3000, \n",
    "          'loss_function': 'MAE', \n",
    "          'verbose': False,\n",
    "         \"random_seed\":123,\n",
    "          \"learning_rate\":0.1,\n",
    "          \"max_depth\":8,\n",
    "          \"task_type\":'GPU',\n",
    "          \"od_type\" : 'Iter',\n",
    "          \"od_wait\": 15\n",
    "          }\n",
    "scores = cv(pool, params)\n",
    "#print(\"Catboostmodels score: {:.4f} ({:.4f})\".format(scores.mean(), scores.std()))\n",
    "scores.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: -3.0926 (0.5857)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, lasso,model_xgb),\n",
    "                                                 meta_model = lasso)\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the TPOT models as basic models, attach QRF and do a stacking prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: -3.3235 (0.3430)\n"
     ]
    }
   ],
   "source": [
    "pipe_a = exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy,validate=False),\n",
    "        MinMaxScaler()\n",
    "    ),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_depth=5, max_features=0.15000000000000002, min_samples_leaf=0.055, min_samples_split=0.505, n_estimators=100)),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_depth=9, max_features=0.15000000000000002, min_samples_leaf=0.255, min_samples_split=0.005, n_estimators=100)),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_depth=5, max_features=0.35000000000000003, min_samples_leaf=0.20500000000000002, min_samples_split=0.35500000000000004, n_estimators=250)),\n",
    "    LGBMRegressor(colsample_bytree=0.75, learning_rate=0.01, max_bin=127, max_depth=4, min_child_weight=15, n_estimators=300, num_leaves=90, objective=\"fair\", reg_alpha=0.05, subsample=0.75, subsample_freq=0, verbosity=-1,n_thread=-1)\n",
    ")\n",
    "\n",
    "pipe_b = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_depth=4, max_features=0.5500000000000002, min_samples_leaf=0.055, min_samples_split=0.455, n_estimators=300)),\n",
    "    MinMaxScaler(),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_depth=5, max_features=0.5500000000000002, min_samples_leaf=0.255, min_samples_split=0.20500000000000002, n_estimators=500)),\n",
    "    LGBMRegressor(colsample_bytree=1.0, learning_rate=0.2, max_bin=63, max_depth=4, min_child_weight=0.001, n_estimators=250, num_leaves=90, objective=\"huber\", reg_alpha=0.007, subsample=0.8, subsample_freq=0, verbosity=-1,n_thread=-1)\n",
    ")\n",
    "\n",
    "pipe_c = exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy,validate=False),\n",
    "        make_union(\n",
    "            FunctionTransformer(copy,validate=False),\n",
    "            FunctionTransformer(copy,validate=False)\n",
    "        )\n",
    "    ),\n",
    "    StackingEstimator(estimator=LGBMRegressor(colsample_bytree=1.0, learning_rate=0.005, max_bin=127, max_depth=5, min_child_weight=1, n_estimators=250, num_leaves=100, objective=\"mape\", reg_alpha=0.01, subsample=0.7, subsample_freq=10, verbosity=-1)),\n",
    "    LGBMRegressor(colsample_bytree=1.0, learning_rate=0.001, max_bin=127, max_depth=4, min_child_weight=10, n_estimators=300, num_leaves=70, objective=\"mape\", reg_alpha=0.05, subsample=0.9, subsample_freq=30, verbosity=-1,n_thread=-1)\n",
    ")\n",
    "\n",
    "\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (pipe_a, pipe_b,pipe_c,model_xgb),\n",
    "                                                 meta_model = ENet)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: -3.3235 (0.3430)\n"
     ]
    }
   ],
   "source": [
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "1) Test shape: (2928, 153), train: (16859, 153)\n",
      "2) Test shape: (2928, 153), train: (5541, 153)\n",
      "3) Test shape: (2928, 153), train: (5741, 153)\n",
      "2017\n",
      "1) Test shape: (2928, 153), train: (16859, 153)\n",
      "2) Test shape: (2928, 153), train: (5128, 153)\n",
      "3) Test shape: (2928, 153), train: (5613, 153)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "preds_all = []\n",
    "\n",
    "for year in [2016,2017]:\n",
    "    print(year)\n",
    "    data_dict = pd.read_pickle(f'../data/processed/data_dict_all.pkl')\n",
    "    X_test = data_dict[year]['X_test_ts'].copy()\n",
    "    \n",
    "    tgt = \"rougher.output.recovery\"\n",
    "    X = data_dict[year]['X_train_ts'].copy()\n",
    "    print(f'1) Test shape: {X_test.shape}, train: {X.shape}')\n",
    "    y = data_dict[year]['y_train'][tgt].dropna()\n",
    "    y = y[(y>5) & (y <100)]\n",
    "    \n",
    "    inds = X.index.intersection(y.index)\n",
    "    X = X.loc[inds]\n",
    "    y = y.loc[inds]\n",
    "        \n",
    "    stacked_averaged_models.fit(X.values, y)\n",
    "    ypred_r = stacked_averaged_models.predict(X_test.values)\n",
    "    preds_r = pd.DataFrame(data = {'date':X_test.index, tgt:ypred_r}).set_index('date')\n",
    "    \n",
    "    tgt = \"final.output.recovery\"\n",
    "    print(f'2) Test shape: {X_test.shape}, train: {X.shape}')\n",
    "    \n",
    "    X = data_dict[year]['X_train_ts'].copy()\n",
    "    X_test = data_dict[year]['X_test_ts'].copy()\n",
    "    y = data_dict[year]['y_train'][tgt].dropna()\n",
    "    \n",
    "    \n",
    "    \n",
    "    y = y[(y>5) & (y <100)]\n",
    "    inds = X.index.intersection(y.index)\n",
    "    X = X.loc[inds]\n",
    "    y = y.loc[inds]\n",
    "    print(f'3) Test shape: {X_test.shape}, train: {X.shape}')\n",
    "    \n",
    "    stacked_averaged_models.fit(X.values, y)\n",
    "    ypred_f = stacked_averaged_models.predict(X_test.values)\n",
    "    preds_f = pd.DataFrame(data = {'date':X_test.index, tgt:ypred_f}).set_index('date')\n",
    "\n",
    "    preds_all.append(preds_r.join(preds_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_preds_sub = pd.concat(preds_all)\n",
    "stacked_preds_sub = stacked_preds_sub.reset_index()\n",
    "stacked_preds_sub['date'] = stacked_preds_sub['date'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "stacked_preds_sub.set_index('date',inplace=True)\n",
    "stacked_preds_sub.drop_duplicates(inplace=True)\n",
    "stacked_preds_sub.to_csv('../results/stacked_sub_3_window.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 153)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89.82622333, 89.75616916, 89.5315029 , ..., 81.3202456 ,\n",
       "       80.8921535 , 81.34507872])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
