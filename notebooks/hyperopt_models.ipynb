{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from ocp_table_tpot.globals import Globals as gd\n",
    "from tpot import TPOTRegressor\n",
    "sys.path.insert(0,'..')\n",
    "from src.models.model import HistoricalMedian,XGBoost,LinearModel,RF,KNN,SVM,mase,TimeSeriesSplitImproved\n",
    "from src.data.split_all_data import DROPCOLS_DIFF_FINAL,DROPCOLS_FINAL\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,Normalizer,StandardScaler,QuantileTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,cross_val_predict\n",
    "from skgarden.quantile import RandomForestQuantileRegressor\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from sklearn.preprocessing import FunctionTransformer,PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from copy import copy\n",
    "from tpot.builtins import StackingEstimator\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from catboost import CatBoostRegressor,Pool,cv\n",
    "\n",
    "\n",
    "df_tsfresh = pd.read_pickle(f'../data/processed/train_test_tsfresh_6.pkl').reset_index(level = 0)\n",
    "data_dict = pd.read_pickle(f'../data/processed/data_dict_all.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2)  train: (13590, 388)\n",
      "after sample() train: (13590, 388)\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "tgt = 'rougher.output.recovery'\n",
    "#cols_drop = X.columns[X.columns.str.contains('p24')]\n",
    "X = data_dict[year][f'X_train_tsclean']#.drop(cols_drop,axis = 1)\n",
    "y = data_dict[year]['y_train']\n",
    "mask = data_dict[year]['mask']\n",
    "\n",
    "X =X.loc[mask.index,:][mask]\n",
    "y = y.loc[mask.index,:][mask]\n",
    "print(f'2)  train: {X.shape}')\n",
    "#X = X.sample(frac=0.4,random_state=123).sort_index().dropna().astype(float)\n",
    "y= y.loc[X.index,tgt]\n",
    "X_filt = X.filter(regex  =\"rougher|dayw|hour\",axis = 1)\n",
    "print(f'after sample() train: {X.shape}')\n",
    "#print(f'after sample() filt train: {X_filt.shape}')\n",
    "# Nmonths_total = 8\n",
    "# Nspl = int(Nmonths_total * 30 / 15)\n",
    "# Nmonths_test = 4\n",
    "# Nmonths_min_train = 2.5\n",
    "# train_splits = Nspl // Nmonths_total*Nmonths_min_train\n",
    "# test_splits=int(Nmonths_test / Nmonths_total*Nspl)\n",
    "# cv = TimeSeriesSplitImproved(n_splits=Nspl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daily_avg_final',\n",
       " 'daily_avg_rougher',\n",
       " 'dayw',\n",
       " 'deriv1_encod_dif_rougher.input.feed_fe',\n",
       " 'deriv1_encod_rel_rougher.input.feed_fe',\n",
       " 'deriv1_encod_rel_rougher.input.feed_zn',\n",
       " 'deriv1_encod_val_rougher.input.feed_fe',\n",
       " 'deriv1_encod_val_rougher.input.feed_pb',\n",
       " 'deriv1_encod_val_rougher.input.feed_zn',\n",
       " 'deriv1_primary_cleaner.input.copper_sulfate',\n",
       " 'deriv1_primary_cleaner.input.depressant',\n",
       " 'deriv1_primary_cleaner.input.xanthate',\n",
       " 'deriv1_primary_cleaner.state.floatbank8_c_air',\n",
       " 'deriv1_primary_cleaner.state.floatbank8_c_level',\n",
       " 'deriv1_primary_cleaner.state.floatbank8_d_level',\n",
       " 'deriv1_rougher.input.feed_fe',\n",
       " 'deriv1_rougher.input.feed_pb',\n",
       " 'deriv1_rougher.input.feed_rate',\n",
       " 'deriv1_rougher.input.feed_size',\n",
       " 'deriv1_rougher.input.feed_sol',\n",
       " 'deriv1_rougher.input.feed_zn',\n",
       " 'deriv1_rougher.input.floatbank10_copper_sulfate',\n",
       " 'deriv1_rougher.input.floatbank10_xanthate',\n",
       " 'deriv1_rougher.input.floatbank11_copper_sulfate',\n",
       " 'deriv1_rougher.input.floatbank11_xanthate',\n",
       " 'deriv1_rougher.state.floatbank10_c_level',\n",
       " 'deriv1_rougher.state.floatbank10_d_air',\n",
       " 'deriv1_rougher.state.floatbank10_d_level',\n",
       " 'deriv2_encod_dif_rougher.input.feed_fe',\n",
       " 'deriv2_encod_rel_rougher.input.feed_fe',\n",
       " 'deriv2_encod_rel_rougher.input.feed_zn',\n",
       " 'deriv2_encod_val_rougher.input.feed_fe',\n",
       " 'deriv2_encod_val_rougher.input.feed_pb',\n",
       " 'deriv2_encod_val_rougher.input.feed_zn',\n",
       " 'deriv2_primary_cleaner.input.copper_sulfate',\n",
       " 'deriv2_primary_cleaner.input.depressant',\n",
       " 'deriv2_primary_cleaner.input.xanthate',\n",
       " 'deriv2_primary_cleaner.state.floatbank8_c_air',\n",
       " 'deriv2_primary_cleaner.state.floatbank8_c_level',\n",
       " 'deriv2_primary_cleaner.state.floatbank8_d_level',\n",
       " 'deriv2_rougher.input.feed_fe',\n",
       " 'deriv2_rougher.input.feed_pb',\n",
       " 'deriv2_rougher.input.feed_rate',\n",
       " 'deriv2_rougher.input.feed_size',\n",
       " 'deriv2_rougher.input.feed_sol',\n",
       " 'deriv2_rougher.input.feed_zn',\n",
       " 'deriv2_rougher.input.floatbank10_copper_sulfate',\n",
       " 'deriv2_rougher.input.floatbank10_xanthate',\n",
       " 'deriv2_rougher.input.floatbank11_copper_sulfate',\n",
       " 'deriv2_rougher.input.floatbank11_xanthate',\n",
       " 'deriv2_rougher.state.floatbank10_c_level',\n",
       " 'deriv2_rougher.state.floatbank10_d_air',\n",
       " 'deriv2_rougher.state.floatbank10_d_level',\n",
       " 'deriv3_encod_dif_rougher.input.feed_fe',\n",
       " 'deriv3_encod_rel_rougher.input.feed_fe',\n",
       " 'deriv3_encod_rel_rougher.input.feed_zn',\n",
       " 'deriv3_encod_val_rougher.input.feed_fe',\n",
       " 'deriv3_encod_val_rougher.input.feed_pb',\n",
       " 'deriv3_encod_val_rougher.input.feed_zn',\n",
       " 'deriv3_primary_cleaner.input.copper_sulfate',\n",
       " 'deriv3_primary_cleaner.input.depressant',\n",
       " 'deriv3_primary_cleaner.input.xanthate',\n",
       " 'deriv3_primary_cleaner.state.floatbank8_c_air',\n",
       " 'deriv3_primary_cleaner.state.floatbank8_c_level',\n",
       " 'deriv3_primary_cleaner.state.floatbank8_d_level',\n",
       " 'deriv3_rougher.input.feed_fe',\n",
       " 'deriv3_rougher.input.feed_pb',\n",
       " 'deriv3_rougher.input.feed_rate',\n",
       " 'deriv3_rougher.input.feed_size',\n",
       " 'deriv3_rougher.input.feed_sol',\n",
       " 'deriv3_rougher.input.feed_zn',\n",
       " 'deriv3_rougher.input.floatbank10_copper_sulfate',\n",
       " 'deriv3_rougher.input.floatbank10_xanthate',\n",
       " 'deriv3_rougher.input.floatbank11_copper_sulfate',\n",
       " 'deriv3_rougher.input.floatbank11_xanthate',\n",
       " 'deriv3_rougher.state.floatbank10_c_level',\n",
       " 'deriv3_rougher.state.floatbank10_d_air',\n",
       " 'deriv3_rougher.state.floatbank10_d_level',\n",
       " 'diff_encod_dif_rougher.input.feed_fe_s2b0',\n",
       " 'diff_encod_dif_rougher.input.feed_fe_s3b1',\n",
       " 'diff_encod_rel_rougher.input.feed_fe_s2b0',\n",
       " 'diff_encod_rel_rougher.input.feed_fe_s3b1',\n",
       " 'diff_encod_rel_rougher.input.feed_zn_s2b0',\n",
       " 'diff_encod_rel_rougher.input.feed_zn_s3b1',\n",
       " 'diff_encod_val_rougher.input.feed_fe_s2b0',\n",
       " 'diff_encod_val_rougher.input.feed_fe_s3b1',\n",
       " 'diff_encod_val_rougher.input.feed_pb_s2b0',\n",
       " 'diff_encod_val_rougher.input.feed_pb_s3b1',\n",
       " 'diff_encod_val_rougher.input.feed_zn_s2b0',\n",
       " 'diff_encod_val_rougher.input.feed_zn_s3b1',\n",
       " 'diff_primary_cleaner.input.copper_sulfate_s2b0',\n",
       " 'diff_primary_cleaner.input.copper_sulfate_s3b1',\n",
       " 'diff_primary_cleaner.input.depressant_s2b0',\n",
       " 'diff_primary_cleaner.input.depressant_s3b1',\n",
       " 'diff_primary_cleaner.input.xanthate_s2b0',\n",
       " 'diff_primary_cleaner.input.xanthate_s3b1',\n",
       " 'diff_primary_cleaner.state.floatbank8_c_air_s2b0',\n",
       " 'diff_primary_cleaner.state.floatbank8_c_air_s3b1',\n",
       " 'diff_primary_cleaner.state.floatbank8_c_level_s2b0',\n",
       " 'diff_primary_cleaner.state.floatbank8_c_level_s3b1',\n",
       " 'diff_primary_cleaner.state.floatbank8_d_level_s2b0',\n",
       " 'diff_primary_cleaner.state.floatbank8_d_level_s3b1',\n",
       " 'diff_rougher.input.feed_fe_s2b0',\n",
       " 'diff_rougher.input.feed_fe_s3b1',\n",
       " 'diff_rougher.input.feed_pb_s2b0',\n",
       " 'diff_rougher.input.feed_pb_s3b1',\n",
       " 'diff_rougher.input.feed_rate_s2b0',\n",
       " 'diff_rougher.input.feed_rate_s3b1',\n",
       " 'diff_rougher.input.feed_size_s2b0',\n",
       " 'diff_rougher.input.feed_size_s3b1',\n",
       " 'diff_rougher.input.feed_sol_s2b0',\n",
       " 'diff_rougher.input.feed_sol_s3b1',\n",
       " 'diff_rougher.input.feed_zn_s2b0',\n",
       " 'diff_rougher.input.feed_zn_s3b1',\n",
       " 'diff_rougher.input.floatbank10_copper_sulfate_s2b0',\n",
       " 'diff_rougher.input.floatbank10_copper_sulfate_s3b1',\n",
       " 'diff_rougher.input.floatbank10_xanthate_s2b0',\n",
       " 'diff_rougher.input.floatbank10_xanthate_s3b1',\n",
       " 'diff_rougher.input.floatbank11_copper_sulfate_s2b0',\n",
       " 'diff_rougher.input.floatbank11_copper_sulfate_s3b1',\n",
       " 'diff_rougher.input.floatbank11_xanthate_s2b0',\n",
       " 'diff_rougher.input.floatbank11_xanthate_s3b1',\n",
       " 'diff_rougher.state.floatbank10_c_level_s2b0',\n",
       " 'diff_rougher.state.floatbank10_c_level_s3b1',\n",
       " 'diff_rougher.state.floatbank10_d_air_s2b0',\n",
       " 'diff_rougher.state.floatbank10_d_air_s3b1',\n",
       " 'diff_rougher.state.floatbank10_d_level_s2b0',\n",
       " 'diff_rougher.state.floatbank10_d_level_s3b1',\n",
       " 'encod_dif_primary_cleaner.input.copper_sulfate',\n",
       " 'encod_dif_primary_cleaner.input.depressant',\n",
       " 'encod_dif_primary_cleaner.input.feed_size',\n",
       " 'encod_dif_primary_cleaner.input.xanthate',\n",
       " 'encod_dif_primary_cleaner.state.floatbank8_a_level',\n",
       " 'encod_dif_rougher.input.feed_fe',\n",
       " 'encod_dif_rougher.input.feed_pb',\n",
       " 'encod_dif_rougher.input.feed_zn',\n",
       " 'encod_rel_primary_cleaner.input.copper_sulfate',\n",
       " 'encod_rel_primary_cleaner.input.depressant',\n",
       " 'encod_rel_primary_cleaner.input.feed_size',\n",
       " 'encod_rel_primary_cleaner.input.xanthate',\n",
       " 'encod_rel_primary_cleaner.state.floatbank8_a_level',\n",
       " 'encod_rel_rougher.input.feed_fe',\n",
       " 'encod_rel_rougher.input.feed_pb',\n",
       " 'encod_rel_rougher.input.feed_zn',\n",
       " 'encod_val_primary_cleaner.input.copper_sulfate',\n",
       " 'encod_val_primary_cleaner.input.depressant',\n",
       " 'encod_val_primary_cleaner.input.feed_size',\n",
       " 'encod_val_primary_cleaner.input.xanthate',\n",
       " 'encod_val_primary_cleaner.state.floatbank8_a_level',\n",
       " 'encod_val_rougher.input.feed_fe',\n",
       " 'encod_val_rougher.input.feed_pb',\n",
       " 'encod_val_rougher.input.feed_zn',\n",
       " 'hour',\n",
       " 'primary_cleaner.input.copper_sulfate',\n",
       " 'primary_cleaner.input.depressant',\n",
       " 'primary_cleaner.input.feed_size',\n",
       " 'primary_cleaner.input.xanthate',\n",
       " 'primary_cleaner.state.floatbank8_a_air',\n",
       " 'primary_cleaner.state.floatbank8_a_level',\n",
       " 'primary_cleaner.state.floatbank8_b_air',\n",
       " 'primary_cleaner.state.floatbank8_b_level',\n",
       " 'primary_cleaner.state.floatbank8_c_air',\n",
       " 'primary_cleaner.state.floatbank8_c_level',\n",
       " 'primary_cleaner.state.floatbank8_d_air',\n",
       " 'primary_cleaner.state.floatbank8_d_level',\n",
       " 'rougher.input.feed_fe',\n",
       " 'rougher.input.feed_pb',\n",
       " 'rougher.input.feed_rate',\n",
       " 'rougher.input.feed_size',\n",
       " 'rougher.input.feed_sol',\n",
       " 'rougher.input.feed_zn',\n",
       " 'rougher.input.floatbank10_copper_sulfate',\n",
       " 'rougher.input.floatbank10_xanthate',\n",
       " 'rougher.input.floatbank11_copper_sulfate',\n",
       " 'rougher.input.floatbank11_xanthate',\n",
       " 'rougher.state.floatbank10_a_air',\n",
       " 'rougher.state.floatbank10_a_level',\n",
       " 'rougher.state.floatbank10_b_air',\n",
       " 'rougher.state.floatbank10_b_level',\n",
       " 'rougher.state.floatbank10_c_air',\n",
       " 'rougher.state.floatbank10_c_level',\n",
       " 'rougher.state.floatbank10_d_air',\n",
       " 'rougher.state.floatbank10_d_level',\n",
       " 'rougher.state.floatbank10_e_air',\n",
       " 'rougher.state.floatbank10_e_level',\n",
       " 'rougher.state.floatbank10_f_air',\n",
       " 'rougher.state.floatbank10_f_level',\n",
       " 'secondary_cleaner.state.floatbank2_a_air',\n",
       " 'secondary_cleaner.state.floatbank2_a_level',\n",
       " 'secondary_cleaner.state.floatbank2_b_air',\n",
       " 'secondary_cleaner.state.floatbank2_b_level',\n",
       " 'secondary_cleaner.state.floatbank3_a_air',\n",
       " 'secondary_cleaner.state.floatbank3_a_level',\n",
       " 'secondary_cleaner.state.floatbank3_b_air',\n",
       " 'secondary_cleaner.state.floatbank3_b_level',\n",
       " 'secondary_cleaner.state.floatbank4_a_air',\n",
       " 'secondary_cleaner.state.floatbank4_a_level',\n",
       " 'secondary_cleaner.state.floatbank4_b_air',\n",
       " 'secondary_cleaner.state.floatbank4_b_level',\n",
       " 'secondary_cleaner.state.floatbank5_a_air',\n",
       " 'secondary_cleaner.state.floatbank5_a_level',\n",
       " 'secondary_cleaner.state.floatbank5_b_air',\n",
       " 'secondary_cleaner.state.floatbank5_b_level',\n",
       " 'secondary_cleaner.state.floatbank6_a_air',\n",
       " 'secondary_cleaner.state.floatbank6_a_level',\n",
       " 'value__kurtosis_p12_primary_cleaner.input.copper_sulfate',\n",
       " 'value__kurtosis_p12_primary_cleaner.input.depressant',\n",
       " 'value__kurtosis_p12_primary_cleaner.input.feed_size',\n",
       " 'value__kurtosis_p12_primary_cleaner.input.xanthate',\n",
       " 'value__kurtosis_p12_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__kurtosis_p12_rougher.input.feed_fe',\n",
       " 'value__kurtosis_p12_rougher.input.feed_pb',\n",
       " 'value__kurtosis_p12_rougher.input.feed_rate',\n",
       " 'value__kurtosis_p12_rougher.input.feed_sol',\n",
       " 'value__kurtosis_p12_rougher.input.feed_zn',\n",
       " 'value__kurtosis_p12_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__kurtosis_p12_rougher.input.floatbank11_xanthate',\n",
       " 'value__kurtosis_p12_rougher.state.floatbank10_b_air',\n",
       " 'value__kurtosis_p12_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__kurtosis_p24_primary_cleaner.input.copper_sulfate',\n",
       " 'value__kurtosis_p24_primary_cleaner.input.depressant',\n",
       " 'value__kurtosis_p24_primary_cleaner.input.feed_size',\n",
       " 'value__kurtosis_p24_primary_cleaner.input.xanthate',\n",
       " 'value__kurtosis_p24_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__kurtosis_p24_rougher.input.feed_fe',\n",
       " 'value__kurtosis_p24_rougher.input.feed_pb',\n",
       " 'value__kurtosis_p24_rougher.input.feed_rate',\n",
       " 'value__kurtosis_p24_rougher.input.feed_sol',\n",
       " 'value__kurtosis_p24_rougher.input.feed_zn',\n",
       " 'value__kurtosis_p24_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__kurtosis_p24_rougher.input.floatbank11_xanthate',\n",
       " 'value__kurtosis_p24_rougher.state.floatbank10_b_air',\n",
       " 'value__kurtosis_p24_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_primary_cleaner.input.copper_sulfate',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_primary_cleaner.input.depressant',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_primary_cleaner.input.feed_size',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_primary_cleaner.input.xanthate',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.feed_fe',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.feed_pb',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.feed_rate',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.feed_sol',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.feed_zn',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.input.floatbank11_xanthate',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_rougher.state.floatbank10_b_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p12_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_primary_cleaner.input.copper_sulfate',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_primary_cleaner.input.depressant',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_primary_cleaner.input.feed_size',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_primary_cleaner.input.xanthate',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.feed_fe',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.feed_pb',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.feed_rate',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.feed_sol',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.feed_zn',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.input.floatbank11_xanthate',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_rougher.state.floatbank10_b_air',\n",
       " 'value__linear_trend__attr_\"slope\"_p24_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__maximum_p6_primary_cleaner.input.copper_sulfate',\n",
       " 'value__maximum_p6_primary_cleaner.input.depressant',\n",
       " 'value__maximum_p6_primary_cleaner.input.feed_size',\n",
       " 'value__maximum_p6_primary_cleaner.input.xanthate',\n",
       " 'value__maximum_p6_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__maximum_p6_rougher.input.feed_fe',\n",
       " 'value__maximum_p6_rougher.input.feed_pb',\n",
       " 'value__maximum_p6_rougher.input.feed_rate',\n",
       " 'value__maximum_p6_rougher.input.feed_sol',\n",
       " 'value__maximum_p6_rougher.input.feed_zn',\n",
       " 'value__maximum_p6_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__maximum_p6_rougher.input.floatbank11_xanthate',\n",
       " 'value__maximum_p6_rougher.state.floatbank10_b_air',\n",
       " 'value__maximum_p6_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__mean_p6_primary_cleaner.input.copper_sulfate',\n",
       " 'value__mean_p6_primary_cleaner.input.depressant',\n",
       " 'value__mean_p6_primary_cleaner.input.feed_size',\n",
       " 'value__mean_p6_primary_cleaner.input.xanthate',\n",
       " 'value__mean_p6_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__mean_p6_rougher.input.feed_fe',\n",
       " 'value__mean_p6_rougher.input.feed_pb',\n",
       " 'value__mean_p6_rougher.input.feed_rate',\n",
       " 'value__mean_p6_rougher.input.feed_sol',\n",
       " 'value__mean_p6_rougher.input.feed_zn',\n",
       " 'value__mean_p6_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__mean_p6_rougher.input.floatbank11_xanthate',\n",
       " 'value__mean_p6_rougher.state.floatbank10_b_air',\n",
       " 'value__mean_p6_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__minimum_p6_primary_cleaner.input.copper_sulfate',\n",
       " 'value__minimum_p6_primary_cleaner.input.depressant',\n",
       " 'value__minimum_p6_primary_cleaner.input.feed_size',\n",
       " 'value__minimum_p6_primary_cleaner.input.xanthate',\n",
       " 'value__minimum_p6_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__minimum_p6_rougher.input.feed_fe',\n",
       " 'value__minimum_p6_rougher.input.feed_pb',\n",
       " 'value__minimum_p6_rougher.input.feed_rate',\n",
       " 'value__minimum_p6_rougher.input.feed_sol',\n",
       " 'value__minimum_p6_rougher.input.feed_zn',\n",
       " 'value__minimum_p6_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__minimum_p6_rougher.input.floatbank11_xanthate',\n",
       " 'value__minimum_p6_rougher.state.floatbank10_b_air',\n",
       " 'value__minimum_p6_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__quantile__q_0.05_p12_primary_cleaner.input.copper_sulfate',\n",
       " 'value__quantile__q_0.05_p12_primary_cleaner.input.depressant',\n",
       " 'value__quantile__q_0.05_p12_primary_cleaner.input.feed_size',\n",
       " 'value__quantile__q_0.05_p12_primary_cleaner.input.xanthate',\n",
       " 'value__quantile__q_0.05_p12_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.feed_fe',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.feed_pb',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.feed_rate',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.feed_sol',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.feed_zn',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__quantile__q_0.05_p12_rougher.input.floatbank11_xanthate',\n",
       " 'value__quantile__q_0.05_p12_rougher.state.floatbank10_b_air',\n",
       " 'value__quantile__q_0.05_p12_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__quantile__q_0.05_p24_primary_cleaner.input.copper_sulfate',\n",
       " 'value__quantile__q_0.05_p24_primary_cleaner.input.depressant',\n",
       " 'value__quantile__q_0.05_p24_primary_cleaner.input.feed_size',\n",
       " 'value__quantile__q_0.05_p24_primary_cleaner.input.xanthate',\n",
       " 'value__quantile__q_0.05_p24_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.feed_fe',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.feed_pb',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.feed_rate',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.feed_sol',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.feed_zn',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__quantile__q_0.05_p24_rougher.input.floatbank11_xanthate',\n",
       " 'value__quantile__q_0.05_p24_rougher.state.floatbank10_b_air',\n",
       " 'value__quantile__q_0.05_p24_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__quantile__q_0.95_p12_primary_cleaner.input.copper_sulfate',\n",
       " 'value__quantile__q_0.95_p12_primary_cleaner.input.depressant',\n",
       " 'value__quantile__q_0.95_p12_primary_cleaner.input.feed_size',\n",
       " 'value__quantile__q_0.95_p12_primary_cleaner.input.xanthate',\n",
       " 'value__quantile__q_0.95_p12_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.feed_fe',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.feed_pb',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.feed_rate',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.feed_sol',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.feed_zn',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__quantile__q_0.95_p12_rougher.input.floatbank11_xanthate',\n",
       " 'value__quantile__q_0.95_p12_rougher.state.floatbank10_b_air',\n",
       " 'value__quantile__q_0.95_p12_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__quantile__q_0.95_p24_primary_cleaner.input.copper_sulfate',\n",
       " 'value__quantile__q_0.95_p24_primary_cleaner.input.depressant',\n",
       " 'value__quantile__q_0.95_p24_primary_cleaner.input.feed_size',\n",
       " 'value__quantile__q_0.95_p24_primary_cleaner.input.xanthate',\n",
       " 'value__quantile__q_0.95_p24_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.feed_fe',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.feed_pb',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.feed_rate',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.feed_sol',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.feed_zn',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__quantile__q_0.95_p24_rougher.input.floatbank11_xanthate',\n",
       " 'value__quantile__q_0.95_p24_rougher.state.floatbank10_b_air',\n",
       " 'value__quantile__q_0.95_p24_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__skewness_p12_primary_cleaner.input.copper_sulfate',\n",
       " 'value__skewness_p12_primary_cleaner.input.depressant',\n",
       " 'value__skewness_p12_primary_cleaner.input.feed_size',\n",
       " 'value__skewness_p12_primary_cleaner.input.xanthate',\n",
       " 'value__skewness_p12_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__skewness_p12_rougher.input.feed_fe',\n",
       " 'value__skewness_p12_rougher.input.feed_pb',\n",
       " 'value__skewness_p12_rougher.input.feed_rate',\n",
       " 'value__skewness_p12_rougher.input.feed_sol',\n",
       " 'value__skewness_p12_rougher.input.feed_zn',\n",
       " 'value__skewness_p12_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__skewness_p12_rougher.input.floatbank11_xanthate',\n",
       " 'value__skewness_p12_rougher.state.floatbank10_b_air',\n",
       " 'value__skewness_p12_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'value__skewness_p24_primary_cleaner.input.copper_sulfate',\n",
       " 'value__skewness_p24_primary_cleaner.input.depressant',\n",
       " 'value__skewness_p24_primary_cleaner.input.feed_size',\n",
       " 'value__skewness_p24_primary_cleaner.input.xanthate',\n",
       " 'value__skewness_p24_primary_cleaner.state.floatbank8_a_air',\n",
       " 'value__skewness_p24_rougher.input.feed_fe',\n",
       " 'value__skewness_p24_rougher.input.feed_pb',\n",
       " 'value__skewness_p24_rougher.input.feed_rate',\n",
       " 'value__skewness_p24_rougher.input.feed_sol',\n",
       " 'value__skewness_p24_rougher.input.feed_zn',\n",
       " 'value__skewness_p24_rougher.input.floatbank10_copper_sulfate',\n",
       " 'value__skewness_p24_rougher.input.floatbank11_xanthate',\n",
       " 'value__skewness_p24_rougher.state.floatbank10_b_air',\n",
       " 'value__skewness_p24_secondary_cleaner.state.floatbank5_a_air',\n",
       " 'week'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.005, random_state=1,max_iter = 2000))\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.01, l1_ratio=.9, random_state=3))\n",
    "\n",
    "CatBoost = CatBoostRegressor(loss_function='MAE',random_seed =123,learning_rate=0.1,max_depth=8,task_type='GPU',od_type = 'Iter',od_wait= 15,iterations = 2000)\n",
    "model_xgb = xgb.XGBRegressor(learning_rate=0.05,\n",
    "                            n_estimators=400,**{'max_depth': 8, 'gamma': '6.915', 'colsample_bytree': '0.501', 'min_child_weight': '5.338'},\n",
    "                            silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='mae',\n",
    "                              learning_rate=0.1, n_estimators=70,random_state=9,\n",
    "                              **{'max_depth': 6, 'num_leaves': 6, 'feature_fraction': '0.650', 'bagging_fraction': '0.291'})\n",
    "rf = RandomForestRegressor(n_estimators=120,max_depth = 5,max_features='auto',n_jobs= -1,criterion = 'mse')\n",
    "#cv_oof(rf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "\n",
    "def cv_boost(model,X_base=None,y=None):\n",
    "    cv = KFold(n_folds, shuffle=False, random_state=42)\n",
    "    scores = []\n",
    "    preds_all_alt = np.empty_like(y)\n",
    "    preds_all_base = np.empty_like(y)\n",
    "    \n",
    "    true_all =np.empty_like(y)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        \n",
    "        #print(y.shape)\n",
    "        # Do the base\n",
    "        evalset = [(X_train.values,y_train.values.reshape(-1,)),(X_valid.values, y_valid.values.reshape(-1,))]\n",
    "        model.fit(X_train.values,y_train.values.reshape(-1,),eval_set=evalset,early_stopping_rounds = 20,verbose = False)\n",
    "        \n",
    "        if (model.__class__ == xgb.sklearn.XGBRegressor):\n",
    "            print(model.best_ntree_limit)\n",
    "            ntree = model.best_ntree_limit\n",
    "            preds  = model.predict(X_valid.values, ntree_limit=ntree )\n",
    "        \n",
    "        if (model.__class__ == lgb.sklearn.LGBMRegressor):\n",
    "            print(model.best_iteration)\n",
    "            ntree = model.best_iteration_\n",
    "            preds  = model.predict(X_valid.values, num_iterations=ntree)\n",
    "        \n",
    "        \n",
    "        preds_all_base[valid_index] = preds\n",
    "        true_all[valid_index] = y_valid\n",
    "        \n",
    "    oof_scores = mase(preds_all_base,true_all)\n",
    "    return oof_scores\n",
    "\n",
    "\n",
    "\n",
    "def cv_lgboost(model,X_base=None,y=None):\n",
    "    cv = KFold(n_folds, shuffle=False, random_state=42)\n",
    "    scores = []\n",
    "    preds_all_alt = np.empty_like(y)\n",
    "    preds_all_base = np.empty_like(y)\n",
    "    \n",
    "    true_all =np.empty_like(y)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        \n",
    "        #print(y.shape)\n",
    "        # Do the base\n",
    "        evalset = [(X_valid.values, y_valid.values.reshape(-1,))]\n",
    "        model.fit(X_train.values,y_train.values.reshape(-1,),eval_set=evalset,early_stopping_rounds = 20,verbose = False)\n",
    "        \n",
    "        ntree = model.best_iteration_\n",
    "        preds  = model.predict(X_valid.values, num_iterations=ntree)\n",
    "        \n",
    "        \n",
    "        preds_all_base[valid_index] = preds\n",
    "        true_all[valid_index] = y_valid\n",
    "        \n",
    "    oof_scores = mase(preds_all_base,true_all)\n",
    "    return oof_scores\n",
    "\n",
    "\n",
    "\n",
    "def cv_oof(model,X_base=None,y=None):\n",
    "    cv = KFold(n_folds, shuffle=False, random_state=42)\n",
    "    preds = cross_val_predict(model,X=X_base,y=y,cv=cv,n_jobs = 1,method = 'predict')\n",
    "    oof_scores = mase(preds,y)\n",
    "    return oof_scores\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=False, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                \n",
    "                instance.fit(np.array(X)[train_index], np.array(y)[train_index])\n",
    "                y_pred = instance.predict(np.array(X)[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "    \n",
    "#cv_oof(model_xgb,X_filt,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try hyperopt for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try hyperopt for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 2.593 params {'num_leaves': 26, 'feature_fraction': '0.222', 'bagging_fraction': '0.888', 'lambda_l1': 3.5819564884805386}\n",
      "Score 2.752 params {'num_leaves': 27, 'feature_fraction': '0.808', 'bagging_fraction': '0.768', 'lambda_l1': 39.022731836716964}\n",
      "Score 2.560 params {'num_leaves': 27, 'feature_fraction': '0.186', 'bagging_fraction': '0.851', 'lambda_l1': 17.90583446846282}\n",
      "Score 2.722 params {'num_leaves': 9, 'feature_fraction': '0.711', 'bagging_fraction': '0.977', 'lambda_l1': 2.150324482963201}\n",
      "Score 2.772 params {'num_leaves': 50, 'feature_fraction': '0.879', 'bagging_fraction': '0.856', 'lambda_l1': 21.10755845033811}\n",
      "Score 2.629 params {'num_leaves': 11, 'feature_fraction': '0.249', 'bagging_fraction': '0.859', 'lambda_l1': 21.963760955647555}\n",
      "Score 2.774 params {'num_leaves': 39, 'feature_fraction': '0.888', 'bagging_fraction': '0.512', 'lambda_l1': 38.748126283885625}\n",
      "Score 2.659 params {'num_leaves': 20, 'feature_fraction': '0.337', 'bagging_fraction': '0.832', 'lambda_l1': 29.55252323869485}\n",
      "Score 2.725 params {'num_leaves': 44, 'feature_fraction': '0.863', 'bagging_fraction': '0.648', 'lambda_l1': 18.47738779996043}\n",
      "Score 2.678 params {'num_leaves': 39, 'feature_fraction': '0.363', 'bagging_fraction': '0.549', 'lambda_l1': 26.265856486144802}\n",
      "Score 2.736 params {'num_leaves': 21, 'feature_fraction': '0.648', 'bagging_fraction': '0.657', 'lambda_l1': 36.31470615628809}\n",
      "Score 2.585 params {'num_leaves': 48, 'feature_fraction': '0.195', 'bagging_fraction': '0.522', 'lambda_l1': 38.838031849151015}\n",
      "Score 2.518 params {'num_leaves': 11, 'feature_fraction': '0.113', 'bagging_fraction': '0.505', 'lambda_l1': 21.124193027796935}\n",
      "Score 2.638 params {'num_leaves': 12, 'feature_fraction': '0.280', 'bagging_fraction': '0.444', 'lambda_l1': 31.76695519202571}\n",
      "Score 2.637 params {'num_leaves': 27, 'feature_fraction': '0.294', 'bagging_fraction': '0.161', 'lambda_l1': 31.068395039183304}\n",
      "Score 2.743 params {'num_leaves': 28, 'feature_fraction': '0.650', 'bagging_fraction': '0.786', 'lambda_l1': 19.30644128259177}\n",
      "Score 2.621 params {'num_leaves': 18, 'feature_fraction': '0.310', 'bagging_fraction': '0.800', 'lambda_l1': 14.041527268379008}\n",
      "Score 2.518 params {'num_leaves': 36, 'feature_fraction': '0.165', 'bagging_fraction': '0.548', 'lambda_l1': 10.229944701427716}\n",
      "Score 2.528 params {'num_leaves': 24, 'feature_fraction': '0.142', 'bagging_fraction': '0.657', 'lambda_l1': 0.25341165714945246}\n",
      "Score 2.629 params {'num_leaves': 17, 'feature_fraction': '0.246', 'bagging_fraction': '0.971', 'lambda_l1': 16.97146771876412}\n",
      "Score 2.672 params {'num_leaves': 33, 'feature_fraction': '0.455', 'bagging_fraction': '0.334', 'lambda_l1': 8.72578242139904}\n",
      "Score 2.494 params {'num_leaves': 34, 'feature_fraction': '0.102', 'bagging_fraction': '0.372', 'lambda_l1': 10.48534583376155}\n",
      "Score 2.627 params {'num_leaves': 31, 'feature_fraction': '0.416', 'bagging_fraction': '0.255', 'lambda_l1': 8.104762453939175}\n",
      "Score 2.504 params {'num_leaves': 41, 'feature_fraction': '0.114', 'bagging_fraction': '0.386', 'lambda_l1': 12.546615754289613}\n",
      "Score 2.723 params {'num_leaves': 44, 'feature_fraction': '0.580', 'bagging_fraction': '0.353', 'lambda_l1': 13.153211671722804}\n",
      "Score 2.497 params {'num_leaves': 44, 'feature_fraction': '0.121', 'bagging_fraction': '0.175', 'lambda_l1': 5.356841244092816}\n",
      "Score 2.688 params {'num_leaves': 34, 'feature_fraction': '0.511', 'bagging_fraction': '0.179', 'lambda_l1': 5.468945081093013}\n",
      "Score 2.617 params {'num_leaves': 47, 'feature_fraction': '0.394', 'bagging_fraction': '0.107', 'lambda_l1': 5.436620233200014}\n",
      "Score 2.503 params {'num_leaves': 37, 'feature_fraction': '0.101', 'bagging_fraction': '0.274', 'lambda_l1': 0.43740024904648145}\n",
      "Score 2.654 params {'num_leaves': 43, 'feature_fraction': '0.487', 'bagging_fraction': '0.234', 'lambda_l1': 4.605884496345611}\n",
      "Score 2.629 params {'num_leaves': 31, 'feature_fraction': '0.219', 'bagging_fraction': '0.438', 'lambda_l1': 9.785665263013836}\n",
      "Score 2.731 params {'num_leaves': 47, 'feature_fraction': '0.759', 'bagging_fraction': '0.101', 'lambda_l1': 24.88420626753891}\n",
      "Score 2.597 params {'num_leaves': 41, 'feature_fraction': '0.158', 'bagging_fraction': '0.191', 'lambda_l1': 15.684266022069115}\n",
      "Score 2.707 params {'num_leaves': 50, 'feature_fraction': '0.548', 'bagging_fraction': '0.309', 'lambda_l1': 3.212387916613315}\n",
      "Score 2.566 params {'num_leaves': 24, 'feature_fraction': '0.196', 'bagging_fraction': '0.395', 'lambda_l1': 7.116540879742267}\n",
      "Score 2.617 params {'num_leaves': 36, 'feature_fraction': '0.270', 'bagging_fraction': '0.134', 'lambda_l1': 10.8168836451948}\n",
      "Score 2.638 params {'num_leaves': 30, 'feature_fraction': '0.348', 'bagging_fraction': '0.208', 'lambda_l1': 1.941359210087895}\n",
      "Score 2.503 params {'num_leaves': 34, 'feature_fraction': '0.104', 'bagging_fraction': '0.591', 'lambda_l1': 15.514006186187746}\n",
      "Score 2.630 params {'num_leaves': 39, 'feature_fraction': '0.225', 'bagging_fraction': '0.724', 'lambda_l1': 23.073936904784965}\n",
      "Score 2.714 params {'num_leaves': 50, 'feature_fraction': '0.820', 'bagging_fraction': '0.464', 'lambda_l1': 6.9827274511559825}\n",
      "Score 2.623 params {'num_leaves': 46, 'feature_fraction': '0.379', 'bagging_fraction': '0.287', 'lambda_l1': 11.646994312411728}\n",
      "Score 2.626 params {'num_leaves': 42, 'feature_fraction': '0.326', 'bagging_fraction': '0.375', 'lambda_l1': 2.0476922698797804}\n",
      "Score 2.669 params {'num_leaves': 25, 'feature_fraction': '0.448', 'bagging_fraction': '0.317', 'lambda_l1': 14.584757191155225}\n",
      "Score 2.731 params {'num_leaves': 45, 'feature_fraction': '0.624', 'bagging_fraction': '0.604', 'lambda_l1': 17.729803625450813}\n",
      "Score 2.532 params {'num_leaves': 38, 'feature_fraction': '0.131', 'bagging_fraction': '0.414', 'lambda_l1': 26.7985501952486}\n",
      "Score 2.736 params {'num_leaves': 33, 'feature_fraction': '0.743', 'bagging_fraction': '0.227', 'lambda_l1': 34.067382277534065}\n",
      "Score 2.563 params {'num_leaves': 22, 'feature_fraction': '0.185', 'bagging_fraction': '0.482', 'lambda_l1': 3.5437783970623684}\n",
      "Score 2.653 params {'num_leaves': 48, 'feature_fraction': '0.266', 'bagging_fraction': '0.913', 'lambda_l1': 0.371253113564852}\n",
      "Score 2.729 params {'num_leaves': 14, 'feature_fraction': '0.697', 'bagging_fraction': '0.147', 'lambda_l1': 20.95906258707338}\n",
      "Score 2.633 params {'num_leaves': 28, 'feature_fraction': '0.308', 'bagging_fraction': '0.715', 'lambda_l1': 6.948700062605919}\n",
      "Score 2.624 params {'num_leaves': 41, 'feature_fraction': '0.231', 'bagging_fraction': '0.595', 'lambda_l1': 9.20451923141704}\n",
      "Score 2.592 params {'num_leaves': 39, 'feature_fraction': '0.144', 'bagging_fraction': '0.351', 'lambda_l1': 16.442492021120415}\n",
      "Score 2.621 params {'num_leaves': 35, 'feature_fraction': '0.421', 'bagging_fraction': '0.114', 'lambda_l1': 19.057611457363326}\n",
      "Score 2.584 params {'num_leaves': 31, 'feature_fraction': '0.182', 'bagging_fraction': '0.262', 'lambda_l1': 12.026899241405447}\n",
      "Score 2.751 params {'num_leaves': 19, 'feature_fraction': '0.585', 'bagging_fraction': '0.512', 'lambda_l1': 22.738630757227547}\n",
      "Score 2.710 params {'num_leaves': 26, 'feature_fraction': '0.509', 'bagging_fraction': '0.434', 'lambda_l1': 13.297264952130117}\n",
      "Score 2.600 params {'num_leaves': 43, 'feature_fraction': '0.211', 'bagging_fraction': '0.170', 'lambda_l1': 27.539845137468753}\n",
      "Score 2.702 params {'num_leaves': 9, 'feature_fraction': '0.361', 'bagging_fraction': '0.542', 'lambda_l1': 5.53370585512098}\n",
      "Score 2.776 params {'num_leaves': 15, 'feature_fraction': '0.836', 'bagging_fraction': '0.292', 'lambda_l1': 8.211045055569297}\n",
      "Score 2.671 params {'num_leaves': 23, 'feature_fraction': '0.468', 'bagging_fraction': '0.224', 'lambda_l1': 10.844851940333637}\n",
      "Score 2.515 params {'num_leaves': 49, 'feature_fraction': '0.117', 'bagging_fraction': '0.469', 'lambda_l1': 24.5255651259278}\n",
      "Score 2.610 params {'num_leaves': 40, 'feature_fraction': '0.284', 'bagging_fraction': '0.350', 'lambda_l1': 1.718520981690066}\n",
      "Score 2.594 params {'num_leaves': 37, 'feature_fraction': '0.169', 'bagging_fraction': '0.702', 'lambda_l1': 28.972560274746}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 2.648 params {'num_leaves': 29, 'feature_fraction': '0.400', 'bagging_fraction': '0.621', 'lambda_l1': 37.07019395267663}\n",
      "Score 2.622 params {'num_leaves': 45, 'feature_fraction': '0.258', 'bagging_fraction': '0.130', 'lambda_l1': 4.411859550299761}\n",
      "Score 2.564 params {'num_leaves': 33, 'feature_fraction': '0.138', 'bagging_fraction': '0.569', 'lambda_l1': 15.005107656009292}\n",
      "Score 2.489 params {'num_leaves': 35, 'feature_fraction': '0.102', 'bagging_fraction': '0.818', 'lambda_l1': 20.3498175903831}\n",
      "Score 2.492 params {'num_leaves': 32, 'feature_fraction': '0.104', 'bagging_fraction': '0.873', 'lambda_l1': 17.960911169114063}\n",
      "Score 2.619 params {'num_leaves': 27, 'feature_fraction': '0.243', 'bagging_fraction': '0.993', 'lambda_l1': 20.106460237529745}\n",
      "Score 2.492 params {'num_leaves': 32, 'feature_fraction': '0.103', 'bagging_fraction': '0.897', 'lambda_l1': 17.649752786345843}\n",
      "Score 2.588 params {'num_leaves': 32, 'feature_fraction': '0.203', 'bagging_fraction': '0.935', 'lambda_l1': 24.603784650501726}\n",
      "Score 2.567 params {'num_leaves': 29, 'feature_fraction': '0.157', 'bagging_fraction': '0.830', 'lambda_l1': 17.732727606604584}\n",
      "Score 2.652 params {'num_leaves': 21, 'feature_fraction': '0.311', 'bagging_fraction': '0.876', 'lambda_l1': 21.62262937657644}\n",
      "Score 2.644 params {'num_leaves': 36, 'feature_fraction': '0.335', 'bagging_fraction': '0.752', 'lambda_l1': 31.6046421981383}\n",
      "Score 2.712 params {'num_leaves': 26, 'feature_fraction': '0.896', 'bagging_fraction': '0.951', 'lambda_l1': 19.98686676459156}\n",
      "Score 2.520 params {'num_leaves': 30, 'feature_fraction': '0.101', 'bagging_fraction': '0.827', 'lambda_l1': 29.811627725435265}\n",
      "Score 2.533 params {'num_leaves': 35, 'feature_fraction': '0.165', 'bagging_fraction': '0.797', 'lambda_l1': 33.03198333212067}\n",
      "Score 2.652 params {'num_leaves': 32, 'feature_fraction': '0.297', 'bagging_fraction': '0.905', 'lambda_l1': 22.620464404163343}\n",
      "Score 2.755 params {'num_leaves': 38, 'feature_fraction': '0.532', 'bagging_fraction': '0.677', 'lambda_l1': 16.663936616648343}\n",
      "Score 2.614 params {'num_leaves': 24, 'feature_fraction': '0.243', 'bagging_fraction': '0.767', 'lambda_l1': 13.268422027320067}\n",
      "Score 2.585 params {'num_leaves': 28, 'feature_fraction': '0.214', 'bagging_fraction': '0.858', 'lambda_l1': 26.04648077739584}\n",
      "Score 2.536 params {'num_leaves': 30, 'feature_fraction': '0.122', 'bagging_fraction': '0.973', 'lambda_l1': 23.96628653863365}\n",
      "Score 2.720 params {'num_leaves': 38, 'feature_fraction': '0.783', 'bagging_fraction': '0.993', 'lambda_l1': 18.297825934824903}\n",
      "Score 2.555 params {'num_leaves': 35, 'feature_fraction': '0.148', 'bagging_fraction': '0.937', 'lambda_l1': 20.868141467470057}\n",
      "Score 2.528 params {'num_leaves': 40, 'feature_fraction': '0.103', 'bagging_fraction': '0.878', 'lambda_l1': 28.300012389382815}\n",
      "Score 2.555 params {'num_leaves': 32, 'feature_fraction': '0.191', 'bagging_fraction': '0.730', 'lambda_l1': 14.131705268294539}\n",
      "Score 2.658 params {'num_leaves': 25, 'feature_fraction': '0.427', 'bagging_fraction': '0.819', 'lambda_l1': 26.31663517314693}\n",
      "Score 2.587 params {'num_leaves': 17, 'feature_fraction': '0.174', 'bagging_fraction': '0.685', 'lambda_l1': 19.004172660447413}\n",
      "Score 2.736 params {'num_leaves': 22, 'feature_fraction': '0.688', 'bagging_fraction': '0.756', 'lambda_l1': 15.797685234058877}\n",
      "Score 2.613 params {'num_leaves': 37, 'feature_fraction': '0.228', 'bagging_fraction': '0.904', 'lambda_l1': 39.853982498725046}\n",
      "Score 2.658 params {'num_leaves': 34, 'feature_fraction': '0.274', 'bagging_fraction': '0.811', 'lambda_l1': 23.721898344490654}\n",
      "Score 2.635 params {'num_leaves': 42, 'feature_fraction': '0.360', 'bagging_fraction': '0.842', 'lambda_l1': 30.087735797649017}\n",
      "Score 2.780 params {'num_leaves': 27, 'feature_fraction': '0.616', 'bagging_fraction': '0.783', 'lambda_l1': 20.188877955874343}\n",
      "Score 2.582 params {'num_leaves': 31, 'feature_fraction': '0.126', 'bagging_fraction': '0.640', 'lambda_l1': 17.327736471497662}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a5b794efb869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             max_evals=150)\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m# For Rougher, tsclean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Score 2.465 params {'num_leaves': 57, 'feature_fraction': '0.048', 'bagging_fraction': '0.170'}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-a5b794efb869>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     16\u001b[0m                               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                               **params)\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_lgboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_filt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score {:.3f} params {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-0563c46d04be>\u001b[0m in \u001b[0;36mcv_lgboost\u001b[1;34m(model, X_base, y)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Do the base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mevalset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevalset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mntree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    640\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    500\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    211\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1753\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1755\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        #'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']), #int(max(2**(int(params['max_depth'])) - params['num_leaves'],0)),\n",
    "        'feature_fraction': \"{:.3f}\".format(params['feature_fraction']),\n",
    "        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction']),\n",
    "        'lambda_l1':params['lambda_l1']\n",
    "        #\"min_data_in_leaf\": int(params['min_data_in_leaf'])\n",
    "\n",
    "    }\n",
    "    \n",
    "    m = lgb.LGBMRegressor(objective='mae',\n",
    "                              learning_rate=0.05, n_estimators=500,random_state=9, \n",
    "                              **params)\n",
    "    score = cv_lgboost(m,X_base = X_filt,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "   # 'max_depth': hp.quniform('max_depth', 2, 8, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 50, 1 ),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.1, 0.9),\n",
    "    'bagging_fraction':hp.uniform('bagging_fraction', 0.1, 1.0),\n",
    "    'lambda_l1':hp.uniform('lambda_l1',0.1,40)\n",
    "    #\"min_data_in_leaf\": hp.loguniform(\"min_data_in_leaf\",1,8)\n",
    "}\n",
    "\n",
    "best_lgbm = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150)\n",
    "# For Rougher, tsclean\n",
    "# Score 2.465 params {'num_leaves': 57, 'feature_fraction': '0.048', 'bagging_fraction': '0.170'}\n",
    "# Score 2.484 params {'num_leaves': 59, 'feature_fraction': '0.035', 'bagging_fraction': '0.411'}\n",
    "# Score 2.495 params {'num_leaves': 10, 'feature_fraction': '0.079', 'bagging_fraction': '0.532'}\n",
    "# Score 2.463 params {'num_leaves': 48, 'feature_fraction': '0.047', 'bagging_fraction': '0.515'}\n",
    "# Score 2.407 params {'num_leaves': 11, 'feature_fraction': '0.057', 'bagging_fraction': '0.113'}\n",
    "# Score 2.437 params {'num_leaves': 33, 'feature_fraction': '0.062', 'bagging_fraction': '0.102'}\n",
    "# With Lambda l1 , tsclean\n",
    "#Score 2.494 params {'num_leaves': 34, 'feature_fraction': '0.102', 'bagging_fraction': '0.372', 'lambda_l1': 10.48534583376155}\n",
    "# Score 2.504 params {'num_leaves': 41, 'feature_fraction': '0.114', 'bagging_fraction': '0.386', 'lambda_l1': 12.546615754289613}\n",
    "# Score 2.497 params {'num_leaves': 44, 'feature_fraction': '0.121', 'bagging_fraction': '0.175', 'lambda_l1': 5.356841244092816}\n",
    "# Score 2.489 params {'num_leaves': 35, 'feature_fraction': '0.102', 'bagging_fraction': '0.818', 'lambda_l1': 20.3498175903831}\n",
    "\n",
    "\n",
    "# For final, tsclean:\n",
    "\n",
    "# Score 1.559 params {'num_leaves': 18, 'feature_fraction': '0.703', 'bagging_fraction': '0.535', 'lambda_l1': 6.7996621167358064}\n",
    "# Score 1.559 params {'num_leaves': 27, 'feature_fraction': '0.549', 'bagging_fraction': '0.206', 'lambda_l1': 1.3634928026875381}\n",
    "# Score 1.550 params {'num_leaves': 43, 'feature_fraction': '0.664', 'bagging_fraction': '0.083', 'lambda_l1': 2.845539961954432}\n",
    "# Score 1.558 params {'num_leaves': 32, 'feature_fraction': '0.190', 'bagging_fraction': '0.340', 'lambda_l1': 1.504006451937044}\n",
    "# Score 1.547 params {'num_leaves': 28, 'feature_fraction': '0.548', 'bagging_fraction': '0.270', 'lambda_l1': 0.2809097693267437}\n",
    "# Score 1.573 params {'num_leaves': 27, 'feature_fraction': '0.448', 'bagging_fraction': '0.314', 'lambda_l1': 4.64151267093926}\n",
    "# Score 1.541 params {'num_leaves': 15, 'feature_fraction': '0.439', 'bagging_fraction': '0.637', 'lambda_l1': 6.530043504380075}\n",
    "# Score 1.545 params {'num_leaves': 40, 'feature_fraction': '0.709', 'bagging_fraction': '0.683', 'lambda_l1': 3.640592310230177}\n",
    "# Score 1.550 params {'num_leaves': 33, 'feature_fraction': '0.586', 'bagging_fraction': '0.442', 'lambda_l1': 7.968821945221622}\n",
    "# Score 1.551 params {'num_leaves': 23, 'feature_fraction': '0.777', 'bagging_fraction': '0.395', 'lambda_l1': 13.389210617182485}\n",
    "# Score 1.557 params {'num_leaves': 18, 'feature_fraction': '0.503', 'bagging_fraction': '0.498', 'lambda_l1': 8.112492754813404}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.model\n",
      "--------------------\n",
      "Thu Feb 28 16:42:45 2019: Reading training data ... \n",
      "Thu Feb 28 16:42:46 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=300\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9963; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:42:56 2019: Calling optimizer with 32 trees and 100 leaves\n",
      "Thu Feb 28 16:43:05 2019: Calling optimizer with 55 trees and 200 leaves\n",
      "Thu Feb 28 16:43:15 2019: Calling optimizer with 77 trees and 300 leaves\n",
      "Thu Feb 28 16:43:15 2019: Writing model: seq#=1\n",
      "Thu Feb 28 16:43:25 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:43:25 2019: Calling optimizer with 92 trees and 400 leaves\n",
      "Thu Feb 28 16:43:25 2019: Writing model: seq#=2\n",
      "\n",
      "Generated 2 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.model-01\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.model-02\n",
      "\n",
      "Thu Feb 28 16:43:25 2019: Done ... \n",
      "elapsed: 38.087\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.model-02\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:43:25 2019: Reading test data ... \n",
      "Thu Feb 28 16:43:26 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\561bd4d6-2c45-47de-b11d-37f6ec82b7651.model-02,#leaf=400,#tree=92\n",
      "Thu Feb 28 16:43:26 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.model\n",
      "--------------------\n",
      "Thu Feb 28 16:43:29 2019: Reading training data ... \n",
      "Thu Feb 28 16:43:30 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=300\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9961; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:43:40 2019: Calling optimizer with 31 trees and 101 leaves\n",
      "Thu Feb 28 16:43:49 2019: Calling optimizer with 52 trees and 200 leaves\n",
      "Thu Feb 28 16:43:59 2019: Calling optimizer with 71 trees and 300 leaves\n",
      "Thu Feb 28 16:43:59 2019: Writing model: seq#=1\n",
      "Thu Feb 28 16:44:08 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:44:08 2019: Calling optimizer with 87 trees and 400 leaves\n",
      "Thu Feb 28 16:44:08 2019: Writing model: seq#=2\n",
      "\n",
      "Generated 2 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.model-01\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.model-02\n",
      "\n",
      "Thu Feb 28 16:44:08 2019: Done ... \n",
      "elapsed: 37.514\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.model-02\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:44:09 2019: Reading test data ... \n",
      "Thu Feb 28 16:44:09 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\d00f0e58-ab8c-43d1-a577-b876df6c90222.model-02,#leaf=400,#tree=87\n",
      "Thu Feb 28 16:44:09 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.model\n",
      "--------------------\n",
      "Thu Feb 28 16:44:12 2019: Reading training data ... \n",
      "Thu Feb 28 16:44:14 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=300\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9967; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:44:23 2019: Calling optimizer with 31 trees and 100 leaves\n",
      "Thu Feb 28 16:44:33 2019: Calling optimizer with 54 trees and 201 leaves\n",
      "Thu Feb 28 16:44:42 2019: Calling optimizer with 72 trees and 300 leaves\n",
      "Thu Feb 28 16:44:42 2019: Writing model: seq#=1\n",
      "Thu Feb 28 16:44:52 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:44:52 2019: Calling optimizer with 92 trees and 400 leaves\n",
      "Thu Feb 28 16:44:52 2019: Writing model: seq#=2\n",
      "\n",
      "Generated 2 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.model-01\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.model-02\n",
      "\n",
      "Thu Feb 28 16:44:52 2019: Done ... \n",
      "elapsed: 38.046\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.model-02\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:44:53 2019: Reading test data ... \n",
      "Thu Feb 28 16:44:53 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\3d7dd665-a0da-49f7-b4d0-cf392d362af63.model-02,#leaf=400,#tree=92\n",
      "Thu Feb 28 16:44:53 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.model\n",
      "--------------------\n",
      "Thu Feb 28 16:44:56 2019: Reading training data ... \n",
      "Thu Feb 28 16:44:58 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=300\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9962; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:45:07 2019: Calling optimizer with 33 trees and 100 leaves\n",
      "Thu Feb 28 16:45:16 2019: Calling optimizer with 55 trees and 200 leaves\n",
      "Thu Feb 28 16:45:25 2019: Calling optimizer with 75 trees and 300 leaves\n",
      "Thu Feb 28 16:45:25 2019: Writing model: seq#=1\n",
      "Thu Feb 28 16:45:35 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:45:35 2019: Calling optimizer with 90 trees and 400 leaves\n",
      "Thu Feb 28 16:45:35 2019: Writing model: seq#=2\n",
      "\n",
      "Generated 2 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.model-01\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.model-02\n",
      "\n",
      "Thu Feb 28 16:45:35 2019: Done ... \n",
      "elapsed: 37.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.model-02\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:45:36 2019: Reading test data ... \n",
      "Thu Feb 28 16:45:36 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\6e430655-11d9-4f53-9fe6-d956198c7ab54.model-02,#leaf=400,#tree=90\n",
      "Thu Feb 28 16:45:36 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.model\n",
      "--------------------\n",
      "Thu Feb 28 16:45:39 2019: Reading training data ... \n",
      "Thu Feb 28 16:45:41 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=300\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9962; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:45:50 2019: Calling optimizer with 33 trees and 100 leaves\n",
      "Thu Feb 28 16:45:59 2019: Calling optimizer with 56 trees and 200 leaves\n",
      "Thu Feb 28 16:46:09 2019: Calling optimizer with 75 trees and 300 leaves\n",
      "Thu Feb 28 16:46:09 2019: Writing model: seq#=1\n",
      "Thu Feb 28 16:46:18 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:46:18 2019: Calling optimizer with 88 trees and 400 leaves\n",
      "Thu Feb 28 16:46:18 2019: Writing model: seq#=2\n",
      "\n",
      "Generated 2 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.model-01\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.model-02\n",
      "\n",
      "Thu Feb 28 16:46:18 2019: Done ... \n",
      "elapsed: 37.263\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.model-02\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:46:19 2019: Reading test data ... \n",
      "Thu Feb 28 16:46:19 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\79e2dbc9-056b-4491-8565-56faed9ed5385.model-02,#leaf=400,#tree=88\n",
      "Thu Feb 28 16:46:19 2019: Done ... \n",
      "\n",
      "Score 1.698 params {'test_interval': 300}\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.model\n",
      "--------------------\n",
      "Thu Feb 28 16:46:22 2019: Reading training data ... \n",
      "Thu Feb 28 16:46:24 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=400\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9963; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:46:33 2019: Calling optimizer with 32 trees and 100 leaves\n",
      "Thu Feb 28 16:46:42 2019: Calling optimizer with 55 trees and 200 leaves\n",
      "Thu Feb 28 16:46:52 2019: Calling optimizer with 77 trees and 300 leaves\n",
      "Thu Feb 28 16:47:01 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:47:01 2019: Calling optimizer with 92 trees and 400 leaves\n",
      "Thu Feb 28 16:47:01 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.model-01\n",
      "\n",
      "Thu Feb 28 16:47:01 2019: Done ... \n",
      "elapsed: 37.551\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:47:02 2019: Reading test data ... \n",
      "Thu Feb 28 16:47:03 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\5dff811f-c51d-428e-9de5-2c47175d18f86.model-01,#leaf=400,#tree=92\n",
      "Thu Feb 28 16:47:03 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.model\n",
      "--------------------\n",
      "Thu Feb 28 16:47:06 2019: Reading training data ... \n",
      "Thu Feb 28 16:47:07 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=400\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9961; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:47:17 2019: Calling optimizer with 31 trees and 101 leaves\n",
      "Thu Feb 28 16:47:26 2019: Calling optimizer with 52 trees and 200 leaves\n",
      "Thu Feb 28 16:47:35 2019: Calling optimizer with 71 trees and 300 leaves\n",
      "Thu Feb 28 16:47:45 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:47:45 2019: Calling optimizer with 87 trees and 400 leaves\n",
      "Thu Feb 28 16:47:45 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.model-01\n",
      "\n",
      "Thu Feb 28 16:47:45 2019: Done ... \n",
      "elapsed: 37.597\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:47:46 2019: Reading test data ... \n",
      "Thu Feb 28 16:47:46 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\501774f9-38f1-4ad5-9801-a7bae5ee181e7.model-01,#leaf=400,#tree=87\n",
      "Thu Feb 28 16:47:46 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.model\n",
      "--------------------\n",
      "Thu Feb 28 16:47:49 2019: Reading training data ... \n",
      "Thu Feb 28 16:47:51 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=400\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9967; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:48:00 2019: Calling optimizer with 31 trees and 100 leaves\n",
      "Thu Feb 28 16:48:09 2019: Calling optimizer with 54 trees and 201 leaves\n",
      "Thu Feb 28 16:48:18 2019: Calling optimizer with 72 trees and 300 leaves\n",
      "Thu Feb 28 16:48:28 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:48:28 2019: Calling optimizer with 92 trees and 400 leaves\n",
      "Thu Feb 28 16:48:28 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.model-01\n",
      "\n",
      "Thu Feb 28 16:48:28 2019: Done ... \n",
      "elapsed: 37.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:48:28 2019: Reading test data ... \n",
      "Thu Feb 28 16:48:29 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\73565be3-5ad4-4d56-bda6-0c691bee025c8.model-01,#leaf=400,#tree=92\n",
      "Thu Feb 28 16:48:29 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.model\n",
      "--------------------\n",
      "Thu Feb 28 16:48:32 2019: Reading training data ... \n",
      "Thu Feb 28 16:48:34 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=400\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9962; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:48:43 2019: Calling optimizer with 33 trees and 100 leaves\n",
      "Thu Feb 28 16:48:52 2019: Calling optimizer with 55 trees and 200 leaves\n",
      "Thu Feb 28 16:49:01 2019: Calling optimizer with 75 trees and 300 leaves\n",
      "Thu Feb 28 16:49:11 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:49:11 2019: Calling optimizer with 90 trees and 400 leaves\n",
      "Thu Feb 28 16:49:11 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.model-01\n",
      "\n",
      "Thu Feb 28 16:49:11 2019: Done ... \n",
      "elapsed: 37.24\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:49:12 2019: Reading test data ... \n",
      "Thu Feb 28 16:49:12 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\a66233b7-21a8-4bae-a76a-8095255985dd9.model-01,#leaf=400,#tree=90\n",
      "Thu Feb 28 16:49:12 2019: Done ... \n",
      "\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.model\n",
      "--------------------\n",
      "Thu Feb 28 16:49:15 2019: Reading training data ... \n",
      "Thu Feb 28 16:49:17 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=400\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9962; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:49:26 2019: Calling optimizer with 33 trees and 100 leaves\n",
      "Thu Feb 28 16:49:35 2019: Calling optimizer with 56 trees and 200 leaves\n",
      "Thu Feb 28 16:49:45 2019: Calling optimizer with 75 trees and 300 leaves\n",
      "Thu Feb 28 16:49:54 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:49:54 2019: Calling optimizer with 88 trees and 400 leaves\n",
      "Thu Feb 28 16:49:54 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.model-01\n",
      "\n",
      "Thu Feb 28 16:49:54 2019: Done ... \n",
      "elapsed: 37.298\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:49:55 2019: Reading test data ... \n",
      "Thu Feb 28 16:49:55 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\27c987a7-f6bc-4d35-b24d-2924eb527dc710.model-01,#leaf=400,#tree=88\n",
      "Thu Feb 28 16:49:55 2019: Done ... \n",
      "\n",
      "Score 1.698 params {'test_interval': 400}\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.train.data.x\n",
      "   train_y_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.model\n",
      "--------------------\n",
      "Thu Feb 28 16:49:58 2019: Reading training data ... \n",
      "Thu Feb 28 16:50:00 2019: Start ... #train=10872\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=LS\n",
      "   max_leaf_forest=400\n",
      "   max_tree=200\n",
      "   opt_interval=100\n",
      "   test_interval=700\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 343x10872, nonzero_ratio=0.9963; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=LS\n",
      "   num_iteration_opt=10\n",
      "   reg_L2=0.1\n",
      "   opt_stepsize=0.5\n",
      "   NormalizeTarget:ON\n",
      "Tree-level: min_pop=10\n",
      "Node split: reg_L2=0.1\n",
      "--------------------\n",
      "Thu Feb 28 16:50:09 2019: Calling optimizer with 32 trees and 100 leaves\n",
      "Thu Feb 28 16:50:18 2019: Calling optimizer with 55 trees and 200 leaves\n",
      "Thu Feb 28 16:50:28 2019: Calling optimizer with 77 trees and 300 leaves\n",
      "Thu Feb 28 16:50:37 2019: AzRgforest: #leaf reached max\n",
      "Thu Feb 28 16:50:37 2019: Calling optimizer with 92 trees and 400 leaves\n",
      "Thu Feb 28 16:50:37 2019: Writing model: seq#=1\n",
      "\n",
      "Generated 1 model file(s): \n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.model-01\n",
      "\n",
      "Thu Feb 28 16:50:37 2019: Done ... \n",
      "elapsed: 37.593\n",
      "\n",
      "\"predict\": \n",
      "   model_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.model-01\n",
      "   test_x_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.test.data.x\n",
      "   prediction_fn=C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Thu Feb 28 16:50:38 2019: Reading test data ... \n",
      "Thu Feb 28 16:50:39 2019: Predicting ... \n",
      "elapsed: 0.011\n",
      "C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.predictions.txt: C:\\Users\\ABIRYU~1\\AppData\\Local\\Temp\\rgf\\ec79184d-dd9b-4273-85f7-87d76c6c8e6d11.model-01,#leaf=400,#tree=92\n",
      "Thu Feb 28 16:50:39 2019: Done ... \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-03ee8f07585d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             max_evals=150)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-03ee8f07585d>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                     verbose=True,**params)\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_rgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score {:.3f} params {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-03ee8f07585d>\u001b[0m in \u001b[0;36mcv_rgf\u001b[1;34m(model, X_base, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#print(y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Do the base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpreds\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\rgf\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_regression_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\rgf\\rgf_model.py\u001b[0m in \u001b[0;36m_fit_regression_task\u001b[1;34m(self, X, y, sample_weight, params)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit_regression_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRGFExecuter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit_multiclass_task\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\rgf\\utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_train_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_model_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\site-packages\\rgf\\utils.py\u001b[0m in \u001b[0;36m_execute_command\u001b[1;34m(self, cmd, force_verbose)\u001b[0m\n\u001b[0;32m    298\u001b[0m                                    \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                                    universal_newlines=True)\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m    828\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m                 \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ocp\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rgf.sklearn import RGFRegressor\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "\n",
    "def cv_rgf(model,X_base=None,y=None):\n",
    "    cv = KFold(n_folds, shuffle=False, random_state=42)\n",
    "    scores = []\n",
    "    preds_all_alt = np.empty_like(y)\n",
    "    preds_all_base = np.empty_like(y)\n",
    "    \n",
    "    true_all =np.empty_like(y)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n",
    "    # print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        \n",
    "        #print(y.shape)\n",
    "        # Do the base\n",
    "        model.fit(X_train.values,y_train.values.reshape(-1,))\n",
    "        \n",
    "        preds  = model.predict(X_valid.values)\n",
    "        \n",
    "        \n",
    "        preds_all_base[valid_index] = preds\n",
    "        true_all[valid_index] = y_valid\n",
    "        \n",
    "    oof_scores = mase(preds_all_base,true_all)\n",
    "    return oof_scores\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'test_interval': int(params['test_interval'])\n",
    "        #'max_depth': int(params['max_depth']),\n",
    "       # 'num_leaves': int(params['num_leaves']), #int(max(2**(int(params['max_depth'])) - params['num_leaves'],0)),\n",
    "        #'feature_fraction': \"{:.3f}\".format(params['feature_fraction']),\n",
    "       # 'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n",
    "        #\"min_data_in_leaf\": int(params['min_data_in_leaf'])\n",
    "\n",
    "    }\n",
    "    \n",
    "    m =RGFRegressor(max_leaf=400,\n",
    "                    algorithm=\"RGF\",\n",
    "                    #test_interval=100,\n",
    "                    loss= 'LS',\n",
    "                    normalize =True,\n",
    "                    verbose=True,**params)\n",
    "    score = cv_rgf(m,X_base = X,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    #'max_leaf': hp.loguniform('num_leaves', 2, 8),\n",
    "    #'test_interval': hp.quniform('test_interval', 100, 1000,100),\n",
    "    #'bagging_fraction':hp.uniform('bagging_fraction', 0.05, 1.0),\n",
    "    #\"min_data_in_leaf\": hp.loguniform(\"min_data_in_leaf\",1,8)\n",
    "}\n",
    "\n",
    "best_rgf = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'gamma': \"{:.3f}\".format(params['gamma']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'subsample':\"{:.3f}\".format(params['subsample']),\n",
    "        'min_child_weight':\"{:.3f}\".format(params['min_child_weight'])\n",
    "\n",
    "    }\n",
    "    # Score 1.226 params {'max_depth': 2, 'gamma': '0.544', 'colsample_bytree': '0.684', 'subsample': '0.932'}\n",
    "\n",
    "    m = xgb.XGBRegressor(learning_rate=0.05,  \n",
    "                             n_estimators=300,                        \n",
    "                             random_state =123,verbose=0,silent=True, n_jobs = -1,**params)\n",
    "    score = cv_boost(m,X_base = X_filt,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 2, 10, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3,1.0),\n",
    "    'min_child_weight':hp.loguniform('min_child_weight', -3, 5),\n",
    "    'subsample':hp.uniform('subsample', 0.3,1.0),\n",
    "    'gamma': hp.uniform('gamma',5, 100.)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=250)\n",
    "#depth 9 gam 7.6 col 0.5\n",
    "\n",
    "\n",
    "# For final!\n",
    "# X_filt\n",
    "# Score 1.693 params {'max_depth': 4, 'gamma': '9.397', 'colsample_bytree': '0.496', 'min_child_weight': '4.803'}\n",
    "# Score 1.711 params {'max_depth': 4, 'gamma': '2.640', 'colsample_bytree': '0.461', 'min_child_weight': '1.456'}\n",
    "# Score 1.698 params {'max_depth': 4, 'gamma': '7.779', 'colsample_bytree': '0.570', 'min_child_weight': '1.442'}\n",
    "# Score 1.703 params {'max_depth': 2, 'gamma': '9.923', 'colsample_bytree': '0.510', 'subsample': '0.425'}\n",
    "# Score 1.704 params {'max_depth': 2, 'gamma': '4.949', 'colsample_bytree': '0.532', 'subsample': '0.868', 'min_child_weight': '6.246'}\n",
    "# Score 1.713 params {'max_depth': 4, 'gamma': '1.359', 'colsample_bytree': '0.380', 'subsample': '0.657', 'min_child_weight': '8.415'}\n",
    "# Score 1.718 params {'max_depth': 3, 'gamma': '3.953', 'colsample_bytree': '0.595', 'subsample': '0.688', 'min_child_weight': '9.466'}\n",
    "# Score 1.677 params {'max_depth': 5, 'gamma': '11.269', 'colsample_bytree': '0.452', 'subsample': '0.577', 'min_child_weight': '17.510'}\n",
    "# Score 1.698 params {'max_depth': 3, 'gamma': '7.361', 'colsample_bytree': '0.493', 'subsample': '0.510', 'min_child_weight': '3.411'}\n",
    "#Lagged X\n",
    "# Score 1.590 params {'max_depth': 7, 'gamma': '84.207', 'colsample_bytree': '0.910', 'subsample': '0.779', 'min_child_weight': '80.419'}\n",
    "# Score 1.598 params {'max_depth': 3, 'gamma': '91.892', 'colsample_bytree': '0.468', 'subsample': '0.337', 'min_child_weight': '56.616'}\n",
    "# Score 1.598 params {'max_depth': 5, 'gamma': '74.885', 'colsample_bytree': '0.450', 'subsample': '0.534', 'min_child_weight': '21.323'}\n",
    "# Score 1.606 params {'max_depth': 5, 'gamma': '70.908', 'colsample_bytree': '0.585', 'subsample': '0.681', 'min_child_weight': '49.926'}\n",
    "# Score 1.609 params {'max_depth': 6, 'gamma': '30.216', 'colsample_bytree': '0.773', 'subsample': '0.804', 'min_child_weight': '65.349'}\n",
    "# Score 1.591 params {'max_depth': 6, 'gamma': '50.306', 'colsample_bytree': '0.736', 'subsample': '0.945', 'min_child_weight': '64.534'}\n",
    "\n",
    "\n",
    "\n",
    "# For rougher\n",
    "\n",
    "# Score 2.611 params {'max_depth': 6, 'gamma': '16.247', 'colsample_bytree': '0.377', 'subsample': '0.694', 'min_child_weight': '12.482'}\n",
    "# Score 2.655 params {'max_depth': 4, 'gamma': '8.024', 'colsample_bytree': '0.363', 'subsample': '0.708', 'min_child_weight': '9.340'}\n",
    "# Score 2.666 params {'max_depth': 4, 'gamma': '16.597', 'colsample_bytree': '0.434', 'subsample': '0.866', 'min_child_weight': '10.709'}\n",
    "# Score 2.615 params {'max_depth': 5, 'gamma': '3.906', 'colsample_bytree': '0.401', 'subsample': '0.760', 'min_child_weight': '9.563'}\n",
    "# Score 2.608 params {'max_depth': 4, 'gamma': '5.102', 'colsample_bytree': '0.344', 'subsample': '0.884', 'min_child_weight': '9.622'}\n",
    "# Score 2.608 params {'max_depth': 6, 'gamma': '18.904', 'colsample_bytree': '0.412', 'subsample': '0.666', 'min_child_weight': '13.043'}\n",
    "# Score 2.603 params {'max_depth': 8, 'gamma': '26.395', 'colsample_bytree': '0.332', 'subsample': '0.752', 'min_child_weight': '19.750'}\n",
    "# Score 2.580 params {'max_depth': 9, 'gamma': '23.565', 'colsample_bytree': '0.536', 'subsample': '0.935', 'min_child_weight': '17.580'}\n",
    "# Score 2.608 params {'max_depth': 8, 'gamma': '22.799', 'colsample_bytree': '0.388', 'subsample': '0.697', 'min_child_weight': '10.327'}\n",
    "# Score 2.599 params {'max_depth': 7, 'gamma': '44.954', 'colsample_bytree': '0.395', 'subsample': '0.993', 'min_child_weight': '133.132'}\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LGBMRegressor()\n",
    "#Xfilt lagged, one lag:\n",
    "# Score 2.480 params {'max_depth': 5, 'num_leaves': 40, 'feature_fraction': '0.453', 'bagging_fraction': '0.276'}\n",
    "# Score 2.500 params {'max_depth': 4, 'num_leaves': 180, 'feature_fraction': '0.322', 'bagging_fraction': '0.150'}\n",
    "# Score 2.490 params {'max_depth': 5, 'num_leaves': 80, 'feature_fraction': '0.440', 'bagging_fraction': '0.666'}\n",
    "# Score 2.490 params {'max_depth': 6, 'num_leaves': 25, 'feature_fraction': '0.555', 'bagging_fraction': '0.257'}\n",
    "# Score 2.484 params {'max_depth': 4, 'num_leaves': 30, 'feature_fraction': '0.658', 'bagging_fraction': '0.863'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try HyperOpt for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QuantileTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8ec57b28190b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQuantileTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_distribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_sc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QuantileTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "scaler = make_pipeline(QuantileTransformer(output_distribution='normal'),StandardScaler(),PCA(whiten=True))\n",
    "X_sc = scaler.fit_transform(X)\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'C': params['C'],\n",
    "      #  'epsilon':\"{:.3f}\".format(params['num_leaves']),\n",
    "        'gamma': params['gamma']\n",
    "    }\n",
    "    m = SVR(kernel = 'rbf',**params)\n",
    "    score = cv_oof(m,X_base = Xsc,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'C': hp.loguniform('C', -5, 5),\n",
    "    'gamma': hp.loguniform('gamma', -2,4 )\n",
    "}\n",
    "\n",
    "best_lgbm = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150)\n",
    "#Score 2.560 params {'C': 15.130365120277071, 'gamma': 51.040699174724814}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try HyperOpt for Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'l2_leaf_reg': params['l2_leaf_reg'],\n",
    "       # 'colsample_bylevel': params['colsample_bylevel'],\n",
    "     #   'random_strength':params['random_strength'],\n",
    "        #'verbose_eval':1000\n",
    "    }\n",
    "    # Score 1.226 params {'max_depth': 2, 'gamma': '0.544', 'colsample_bytree': '0.684', 'subsample': '0.932'}\n",
    "    m = CatBoostRegressor(loss_function='Quantile:alpha=0.6',random_seed =123,learning_rate=0.4,task_type='GPU',od_type = 'Iter',od_wait= 15,iterations = 1000,\n",
    "                          max_bin=128,**params)\n",
    "\n",
    "    score = cv_catboost(m,X_base = X_filt,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 5, 1),\n",
    "    #'colsample_bylevel': hp.uniform('colsample_bylevel', 0.3, 1.0),\n",
    "    'l2_leaf_reg': hp.loguniform('l2_leaf_reg', -8, 1),\n",
    "    #'random_strength':hp.loguniform('random_strength', -5, 5)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try hyperopt KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = make_pipeline(QuantileTransformer(output_distribution='normal'),StandardScaler(),PCA(whiten=True))\n",
    "X_sc = scaler.fit_transform(X)\n",
    "    \n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'n_neighbors': int(params['n_neighbors']),\n",
    "        'weights':params['weights'],\n",
    "        'leaf_size': params['leaf_size']\n",
    "    }\n",
    "    \n",
    "    \n",
    "    m = KNeighborsRegressor(n_jobs = -1,**params)\n",
    "    score = cv_oof(m,X_base = X_sc,y=y)\n",
    "    print(\"Score {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'n_neighbors': hp.quniform('n_neighbors',3, 256,2),\n",
    "    'leaf_size': hp.quniform('lef_size', 14,50,2 ),\n",
    "    'weights':hp.choice('weights', ['uniform','distance'])\n",
    "}\n",
    "\n",
    "best_lgbm = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=150)\n",
    "# Score 3.224 params {'n_neighbors': 198, 'weights': 'distance', 'leaf_size': 36.0}\n",
    "# Score 3.194 params {'n_neighbors': 254, 'weights': 'distance', 'leaf_size': 16.0}\n",
    "# Score 3.196 params {'n_neighbors': 250, 'weights': 'distance', 'leaf_size': 18.0}\n",
    "# Score 3.202 params {'n_neighbors': 238, 'weights': 'distance', 'leaf_size': 48.0}\n",
    "# Score 3.215 params {'n_neighbors': 214, 'weights': 'distance', 'leaf_size': 30.0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.plot(figsize  = (20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.apply(pd.isna,axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[tgt].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
